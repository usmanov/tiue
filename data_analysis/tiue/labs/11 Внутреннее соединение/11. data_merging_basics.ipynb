{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Joining data with pandas"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d702867a9407cf90"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data merging basics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3296083285a187eb"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:19.277417Z",
     "start_time": "2024-01-06T05:11:15.636570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File opened successfully!\n"
     ]
    }
   ],
   "source": [
    "# Assuming your Jupyter Notebook is in the exercises folder\n",
    "# You want to access the file taxi_owners.p in the datasets folder\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Navigate to the datasets folder\n",
    "datasets_directory = os.path.join(current_directory, '..', 'datasets')\n",
    "\n",
    "# Check if the file exists in the datasets folder\n",
    "file_path = os.path.join(datasets_directory, 'taxi_owners.p')\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # File exists, so open it\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    # Work with the 'data' object as needed\n",
    "    print(\"File opened successfully!\")\n",
    "else:\n",
    "    print(\"File not found.\")\n",
    "taxi_owners = data"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "        rid   vid             owner                 address    zip\n0     T6285  6285    AGEAN TAXI LLC     4536 N. ELSTON AVE.  60630\n1     T4862  4862      MANGIB CORP.  5717 N. WASHTENAW AVE.  60659\n2     T1495  1495     FUNRIDE, INC.     3351 W. ADDISON ST.  60618\n3     T4231  4231      ALQUSH CORP.   6611 N. CAMPBELL AVE.  60645\n4     T5971  5971    EUNIFFORD INC.     3351 W. ADDISON ST.  60618\n...     ...   ...               ...                     ...    ...\n3514  T4453  4453   IMAGIN CAB CORP     3351 W. ADDISON ST.  60618\n3515   T121   121  TRIBECA CAB CORP     4536 N. ELSTON AVE.  60630\n3516  T3465  3465  AMIR EXPRESS INC     3351 W. ADDISON ST.  60618\n3517  T1962  1962  KARY CAB COMPANY     4707 N. KENTON AVE.  60630\n3518  T1031  1031       NECT 42 LLC    6500 N. WESTERN AVE.  60645\n\n[3519 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rid</th>\n      <th>vid</th>\n      <th>owner</th>\n      <th>address</th>\n      <th>zip</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>T6285</td>\n      <td>6285</td>\n      <td>AGEAN TAXI LLC</td>\n      <td>4536 N. ELSTON AVE.</td>\n      <td>60630</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>T4862</td>\n      <td>4862</td>\n      <td>MANGIB CORP.</td>\n      <td>5717 N. WASHTENAW AVE.</td>\n      <td>60659</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>T1495</td>\n      <td>1495</td>\n      <td>FUNRIDE, INC.</td>\n      <td>3351 W. ADDISON ST.</td>\n      <td>60618</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>T4231</td>\n      <td>4231</td>\n      <td>ALQUSH CORP.</td>\n      <td>6611 N. CAMPBELL AVE.</td>\n      <td>60645</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>T5971</td>\n      <td>5971</td>\n      <td>EUNIFFORD INC.</td>\n      <td>3351 W. ADDISON ST.</td>\n      <td>60618</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3514</th>\n      <td>T4453</td>\n      <td>4453</td>\n      <td>IMAGIN CAB CORP</td>\n      <td>3351 W. ADDISON ST.</td>\n      <td>60618</td>\n    </tr>\n    <tr>\n      <th>3515</th>\n      <td>T121</td>\n      <td>121</td>\n      <td>TRIBECA CAB CORP</td>\n      <td>4536 N. ELSTON AVE.</td>\n      <td>60630</td>\n    </tr>\n    <tr>\n      <th>3516</th>\n      <td>T3465</td>\n      <td>3465</td>\n      <td>AMIR EXPRESS INC</td>\n      <td>3351 W. ADDISON ST.</td>\n      <td>60618</td>\n    </tr>\n    <tr>\n      <th>3517</th>\n      <td>T1962</td>\n      <td>1962</td>\n      <td>KARY CAB COMPANY</td>\n      <td>4707 N. KENTON AVE.</td>\n      <td>60630</td>\n    </tr>\n    <tr>\n      <th>3518</th>\n      <td>T1031</td>\n      <td>1031</td>\n      <td>NECT 42 LLC</td>\n      <td>6500 N. WESTERN AVE.</td>\n      <td>60645</td>\n    </tr>\n  </tbody>\n</table>\n<p>3519 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_owners"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:19.401662Z",
     "start_time": "2024-01-06T05:11:19.285206Z"
    }
   },
   "id": "376963d06fece624",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File opened successfully!\n"
     ]
    }
   ],
   "source": [
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Navigate to the datasets folder\n",
    "datasets_directory = os.path.join(current_directory, '..', 'datasets')\n",
    "\n",
    "# Check if the file exists in the datasets folder\n",
    "file_path = os.path.join(datasets_directory, 'taxi_vehicles.p')\n",
    "\n",
    "try:\n",
    "    if os.path.exists(file_path):\n",
    "        # File exists, so open it\n",
    "        with open(file_path, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "        # Work with the 'data' object as needed\n",
    "        print(\"File opened successfully!\")\n",
    "        taxi_vehicles = data\n",
    "    else:\n",
    "        print(\"File not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    taxi_vehicles = None  # Assigning None to 'taxi_vehicles' if an error occurs\n",
    "\n",
    "taxi_veh = data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:19.404907Z",
     "start_time": "2024-01-06T05:11:19.308499Z"
    }
   },
   "id": "c49901c944eadfb",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       vid     make    model  year  fuel_type                owner\n0     2767   TOYOTA    CAMRY  2013     HYBRID       SEYED M. BADRI\n1     1411   TOYOTA     RAV4  2017     HYBRID          DESZY CORP.\n2     6500   NISSAN   SENTRA  2019   GASOLINE       AGAPH CAB CORP\n3     2746   TOYOTA    CAMRY  2013     HYBRID  MIDWEST CAB CO, INC\n4     5922   TOYOTA    CAMRY  2013     HYBRID       SUMETTI CAB CO\n...    ...      ...      ...   ...        ...                  ...\n3514  5902   TOYOTA    CAMRY  2013     HYBRID            SAFAR INC\n3515  1407  HYUNDAI  ELANTRA  2018   GASOLINE    MYKONOS CAB CORP.\n3516   854   TOYOTA    CAMRY  2012     HYBRID      JOELIZ CORP INC\n3517  6274   TOYOTA    CAMRY  2012     HYBRID          A K O S INC\n3518  4675     FORD   ESCAPE  2011  FLEX FUEL           MAJAZ CORP\n\n[3519 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>vid</th>\n      <th>make</th>\n      <th>model</th>\n      <th>year</th>\n      <th>fuel_type</th>\n      <th>owner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2767</td>\n      <td>TOYOTA</td>\n      <td>CAMRY</td>\n      <td>2013</td>\n      <td>HYBRID</td>\n      <td>SEYED M. BADRI</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1411</td>\n      <td>TOYOTA</td>\n      <td>RAV4</td>\n      <td>2017</td>\n      <td>HYBRID</td>\n      <td>DESZY CORP.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6500</td>\n      <td>NISSAN</td>\n      <td>SENTRA</td>\n      <td>2019</td>\n      <td>GASOLINE</td>\n      <td>AGAPH CAB CORP</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2746</td>\n      <td>TOYOTA</td>\n      <td>CAMRY</td>\n      <td>2013</td>\n      <td>HYBRID</td>\n      <td>MIDWEST CAB CO, INC</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5922</td>\n      <td>TOYOTA</td>\n      <td>CAMRY</td>\n      <td>2013</td>\n      <td>HYBRID</td>\n      <td>SUMETTI CAB CO</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3514</th>\n      <td>5902</td>\n      <td>TOYOTA</td>\n      <td>CAMRY</td>\n      <td>2013</td>\n      <td>HYBRID</td>\n      <td>SAFAR INC</td>\n    </tr>\n    <tr>\n      <th>3515</th>\n      <td>1407</td>\n      <td>HYUNDAI</td>\n      <td>ELANTRA</td>\n      <td>2018</td>\n      <td>GASOLINE</td>\n      <td>MYKONOS CAB CORP.</td>\n    </tr>\n    <tr>\n      <th>3516</th>\n      <td>854</td>\n      <td>TOYOTA</td>\n      <td>CAMRY</td>\n      <td>2012</td>\n      <td>HYBRID</td>\n      <td>JOELIZ CORP INC</td>\n    </tr>\n    <tr>\n      <th>3517</th>\n      <td>6274</td>\n      <td>TOYOTA</td>\n      <td>CAMRY</td>\n      <td>2012</td>\n      <td>HYBRID</td>\n      <td>A K O S INC</td>\n    </tr>\n    <tr>\n      <th>3518</th>\n      <td>4675</td>\n      <td>FORD</td>\n      <td>ESCAPE</td>\n      <td>2011</td>\n      <td>FLEX FUEL</td>\n      <td>MAJAZ CORP</td>\n    </tr>\n  </tbody>\n</table>\n<p>3519 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_veh"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:19.505910Z",
     "start_time": "2024-01-06T05:11:19.328979Z"
    }
   },
   "id": "a7b16401d3760fff",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Your first inner join\n",
    "You have been tasked with figuring out what the most popular types of fuel used in Chicago taxis are. To complete the analysis, you need to merge the `taxi_owners` and `taxi_veh` tables together on the `vid` column. You can then use the merged table along with the `.value_counts()` method to find the most common `fuel_type`.\n",
    "\n",
    "Since you'll be working with pandas throughout the course, the package will be preloaded for you as pd in each exercise in this course. Also the `taxi_owners` and `taxi_veh` DataFrames are loaded for you."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb38e431ad6dd830"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instructions 1/3\n",
    "1. Merge `taxi_owners` with `taxi_veh` on the column `vid`, and save the result to `taxi_own_veh`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c0655f543c5659c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rid', 'vid', 'owner_x', 'address', 'zip', 'make', 'model', 'year',\n",
      "       'fuel_type', 'owner_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Merge the taxi_owners and taxi_veh tables\n",
    "taxi_own_veh = taxi_owners.merge(taxi_veh, on='vid')\n",
    "\n",
    "# Print the column names of the taxi_own_veh\n",
    "print(taxi_own_veh.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:19.526941Z",
     "start_time": "2024-01-06T05:11:19.340620Z"
    }
   },
   "id": "6fb0598bb0384d8f",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instructions 2/3\n",
    "\n",
    "Set the left and right table suffixes for overlapping columns of the merge to `_own` and `_veh`, respectively."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36699a12d6a5d194"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rid', 'vid', 'owner_own', 'address', 'zip', 'make', 'model', 'year',\n",
      "       'fuel_type', 'owner_veh'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Merge the taxi_owners and taxi_veh tables setting a suffix\n",
    "taxi_own_veh = taxi_owners.merge(taxi_veh, on='vid', suffixes=('_own', '_veh'))\n",
    "\n",
    "# Print the column names of taxi_own_veh\n",
    "print(taxi_own_veh.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:19.530097Z",
     "start_time": "2024-01-06T05:11:19.361834Z"
    }
   },
   "id": "d8c492c719dfacbc",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instructions 3/3\n",
    "\n",
    "Select the `fuel_type` column from `taxi_own_veh` and print the `value_counts()` to find the most popular `fuel_types` used."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79a007f0cc0220a4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYBRID                    2792\n",
      "GASOLINE                   611\n",
      "FLEX FUEL                   89\n",
      "COMPRESSED NATURAL GAS      27\n",
      "Name: fuel_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Merge the taxi_owners and taxi_veh tables setting a suffix\n",
    "taxi_own_veh = taxi_owners.merge(taxi_veh, on='vid', suffixes=('_own','_veh'))\n",
    "\n",
    "# Print the value_counts to find the most popular fuel_type\n",
    "print(taxi_own_veh['fuel_type'].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:19.548475Z",
     "start_time": "2024-01-06T05:11:19.373684Z"
    }
   },
   "id": "e19177dd9c8d5f1f",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'ward.p' opened and stored in 'wards' DataFrame.\n",
      "   ward                   alderman                            address    zip\n",
      "0     1         Proco \"Joe\" Moreno          2058 NORTH WESTERN AVENUE  60647\n",
      "1     2              Brian Hopkins         1400 NORTH  ASHLAND AVENUE  60622\n",
      "2     3                 Pat Dowell            5046 SOUTH STATE STREET  60609\n",
      "3     4           William D. Burns    435 EAST 35TH STREET, 1ST FLOOR  60616\n",
      "4     5         Leslie A. Hairston              2325 EAST 71ST STREET  60649\n",
      "5     6         Roderick T. Sawyer   8001 S. MARTIN LUTHER KING DRIVE  60619\n",
      "6     7        Gregory I. Mitchell              2249 EAST 95TH STREET  60617\n",
      "7     8         Michelle A. Harris    8539 SOUTH COTTAGE GROVE AVENUE  60619\n",
      "8     9           Anthony A. Beale                34 EAST 112TH PLACE  60628\n",
      "9    10      Susan Sadlowski Garza           10500 SOUTH EWING AVENUE  60617\n",
      "10   11     Patrick Daley Thompson          3659 SOUTH HALSTED STREET  60609\n",
      "11   12            George Cardenas           3476 SOUTH ARCHER AVENUE  60608\n",
      "12   13                Marty Quinn            6500 SOUTH PULASKI ROAD  60629\n",
      "13   14            Edward M. Burke              2650 WEST 51ST STREET  60632\n",
      "14   15           Raymond A. Lopez              1650 WEST 63RD STREET  60636\n",
      "15   16            Toni L. Foulkes              3045 WEST 63RD STREET  60629\n",
      "16   17             David H. Moore          7313 SOUTH ASHLAND AVENUE  60636\n",
      "17   18          Derrick G. Curtis            8359 SOUTH PULASKI ROAD  60652\n",
      "18   19          Matthew J. O'Shea         10400 SOUTH WESTERN AVENUE  60643\n",
      "19   20          Willie B. Cochran    6357 SOUTH COTTAGE GROVE AVENUE  60637\n",
      "20   21    Howard B. Brookins, Jr.  9011 SOUTH ASHLAND AVENUE, UNIT B  60620\n",
      "21   22              Ricardo Munoz        2500 SOUTH ST. LOUIS AVENUE  60623\n",
      "22   23        Michael R. Zalewski           6247 SOUTH ARCHER AVENUE  60638\n",
      "23   24         Michael Scott, Jr.           1158 SOUTH KEELER AVENUE  60624\n",
      "24   25       Daniel \"Danny\" Solis      1800 SOUTH BLUE ISLAND AVENUE  60608\n",
      "25   26          Roberto Maldonado          2511 WEST DIVISION STREET  60622\n",
      "26   27        Walter Burnett, Jr.             4 NORTH WESTERN AVENUE  60612\n",
      "27   28             Jason C. Ervin              2602 WEST 16TH STREET  60612\n",
      "28   29           Chris Taliaferro             6272 WEST NORTH AVENUE  60639\n",
      "29   30          Ariel E. Reyboras        3559 NORTH MILWAUKEE AVENUE  60641\n",
      "30   31  Milagros \"Milly\" Santiago            2521 NORTH PULASKI ROAD  60639\n",
      "31   32           Scott Waguespack         2657 NORTH CLYBOURN AVENUE  60614\n",
      "32   33               Deborah Mell         3001 WEST IRVING PARK ROAD  60618\n",
      "33   34           Carrie M. Austin              507 WEST 111TH STREET  60628\n",
      "34   35        Carlos Ramirez-Rosa           2710 NORTH SAWYER AVENUE  60647\n",
      "35   36           Gilbert Villegas                 6934 WEST DIVERSEY  60607\n",
      "36   37              Emma M. Mitts           4924 WEST CHICAGO AVENUE  60651\n",
      "37   38           Nicholas Sposato          3821  NORTH HARLEM AVENUE  60634\n",
      "38   39           Margaret Laurino          4404 WEST LAWRENCE AVENUE  60630\n",
      "39   40        Patrick J. O'Connor          5850 NORTH LINCOLN AVENUE  60659\n",
      "40   41      Anthony V. Napolitano           7442 NORTH HARLEM AVENUE  60631\n",
      "41   42             Brendan Reilly   325 WEST HURON STREET, SUITE 510  60654\n",
      "42   43             Michelle Smith          2523 NORTH HALSTED STREET  60614\n",
      "43   44                 Tom Tunney        3223 NORTH SHEFFIELD AVENUE  60657\n",
      "44   45              John S. Arena        4754 NORTH MILWAUKEE AVENUE  60630\n",
      "45   46            James Cappleman         4544 NORTH BROADWAY AVENUE  60640\n",
      "46   47                Ameya Pawar          4243 NORTH LINCOLN AVENUE  60618\n",
      "47   48             Harry Osterman         5533 NORTH BROADWAY AVENUE  60640\n",
      "48   49                  Joe Moore        7356 NORTH GREENVIEW AVENUE  60626\n",
      "49   50       Debra L. Silverstein    2949 WEST DEVON AVENUE, SUITE A  60659\n"
     ]
    }
   ],
   "source": [
    "# File path for wards.p\n",
    "ward_file_path = os.path.join(datasets_directory, 'ward.p')\n",
    "\n",
    "# Load wards.p if it exists as a DataFrame named 'wards'\n",
    "if os.path.exists(ward_file_path):\n",
    "    with open(ward_file_path, 'rb') as file:\n",
    "        wards = pd.DataFrame(pickle.load(file))\n",
    "        print(\"File 'ward.p' opened and stored in 'wards' DataFrame.\")\n",
    "else:\n",
    "    print(\"File 'ward.p' not found.\")\n",
    "\n",
    "print(wards)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:19.883328Z",
     "start_time": "2024-01-06T05:11:19.389599Z"
    }
   },
   "id": "1ba1034993f99348",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'census.p' opened and stored in 'census' DataFrame.\n",
      "  ward  pop_2000  pop_2010 change                                  address  \\\n",
      "0    1     52951     56149     6%              2765 WEST SAINT MARY STREET   \n",
      "1    2     54361     55805     3%                 WM WASTE MANAGEMENT 1500   \n",
      "2    3     40385     53039    31%                      17 EAST 38TH STREET   \n",
      "3    4     51953     54589     5%  31ST ST HARBOR BUILDING LAKEFRONT TRAIL   \n",
      "4    5     55302     51455    -7%  JACKSON PARK LAGOON SOUTH CORNELL DRIVE   \n",
      "\n",
      "     zip  \n",
      "0  60647  \n",
      "1  60622  \n",
      "2  60653  \n",
      "3  60653  \n",
      "4  60637  \n"
     ]
    }
   ],
   "source": [
    "# File path for census.p\n",
    "census_file_path = os.path.join(datasets_directory, 'census.p')\n",
    "\n",
    "# Load census.p if it exists as a DataFrame named 'census'\n",
    "if os.path.exists(census_file_path):\n",
    "    with open(census_file_path, 'rb') as file:\n",
    "        census = pd.DataFrame(pickle.load(file))\n",
    "        print(\"File 'census.p' opened and stored in 'census' DataFrame.\")\n",
    "else:\n",
    "    print(\"File 'census.p' not found.\")\n",
    "    \n",
    "print(census.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:20.044588Z",
     "start_time": "2024-01-06T05:11:19.676307Z"
    }
   },
   "id": "20e43eee91d93dee",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inner joins and number of rows returned\n",
    "\n",
    "All the merges you have studied to this point are called inner joins. It is necessary to understand that inner joins only return the rows with matching values in both tables. You will explore this further by reviewing the merge between the `wards` and `census` tables, then comparing it to merges of copies of these tables that are slightly altered, named `wards_altered`, and `census_altered`. The first row of the wards column has been changed in the altered tables. You will examine how this affects the merge between them. The tables have been loaded for you.\n",
    "\n",
    "For this exercise, it is important to know that the `wards` and `census` tables start with 50 rows."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d988cf250f16769"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instructions 1/3\n",
    "\n",
    "Merge `wards` and `census` on the `ward` column and save the result to `wards_census`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65063119c863a2e4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wards_census table shape: (50, 9)\n",
      "   ward                   alderman                          address_x  zip_x  \\\n",
      "0     1         Proco \"Joe\" Moreno          2058 NORTH WESTERN AVENUE  60647   \n",
      "1     2              Brian Hopkins         1400 NORTH  ASHLAND AVENUE  60622   \n",
      "2     3                 Pat Dowell            5046 SOUTH STATE STREET  60609   \n",
      "3     4           William D. Burns    435 EAST 35TH STREET, 1ST FLOOR  60616   \n",
      "4     5         Leslie A. Hairston              2325 EAST 71ST STREET  60649   \n",
      "5     6         Roderick T. Sawyer   8001 S. MARTIN LUTHER KING DRIVE  60619   \n",
      "6     7        Gregory I. Mitchell              2249 EAST 95TH STREET  60617   \n",
      "7     8         Michelle A. Harris    8539 SOUTH COTTAGE GROVE AVENUE  60619   \n",
      "8     9           Anthony A. Beale                34 EAST 112TH PLACE  60628   \n",
      "9    10      Susan Sadlowski Garza           10500 SOUTH EWING AVENUE  60617   \n",
      "10   11     Patrick Daley Thompson          3659 SOUTH HALSTED STREET  60609   \n",
      "11   12            George Cardenas           3476 SOUTH ARCHER AVENUE  60608   \n",
      "12   13                Marty Quinn            6500 SOUTH PULASKI ROAD  60629   \n",
      "13   14            Edward M. Burke              2650 WEST 51ST STREET  60632   \n",
      "14   15           Raymond A. Lopez              1650 WEST 63RD STREET  60636   \n",
      "15   16            Toni L. Foulkes              3045 WEST 63RD STREET  60629   \n",
      "16   17             David H. Moore          7313 SOUTH ASHLAND AVENUE  60636   \n",
      "17   18          Derrick G. Curtis            8359 SOUTH PULASKI ROAD  60652   \n",
      "18   19          Matthew J. O'Shea         10400 SOUTH WESTERN AVENUE  60643   \n",
      "19   20          Willie B. Cochran    6357 SOUTH COTTAGE GROVE AVENUE  60637   \n",
      "20   21    Howard B. Brookins, Jr.  9011 SOUTH ASHLAND AVENUE, UNIT B  60620   \n",
      "21   22              Ricardo Munoz        2500 SOUTH ST. LOUIS AVENUE  60623   \n",
      "22   23        Michael R. Zalewski           6247 SOUTH ARCHER AVENUE  60638   \n",
      "23   24         Michael Scott, Jr.           1158 SOUTH KEELER AVENUE  60624   \n",
      "24   25       Daniel \"Danny\" Solis      1800 SOUTH BLUE ISLAND AVENUE  60608   \n",
      "25   26          Roberto Maldonado          2511 WEST DIVISION STREET  60622   \n",
      "26   27        Walter Burnett, Jr.             4 NORTH WESTERN AVENUE  60612   \n",
      "27   28             Jason C. Ervin              2602 WEST 16TH STREET  60612   \n",
      "28   29           Chris Taliaferro             6272 WEST NORTH AVENUE  60639   \n",
      "29   30          Ariel E. Reyboras        3559 NORTH MILWAUKEE AVENUE  60641   \n",
      "30   31  Milagros \"Milly\" Santiago            2521 NORTH PULASKI ROAD  60639   \n",
      "31   32           Scott Waguespack         2657 NORTH CLYBOURN AVENUE  60614   \n",
      "32   33               Deborah Mell         3001 WEST IRVING PARK ROAD  60618   \n",
      "33   34           Carrie M. Austin              507 WEST 111TH STREET  60628   \n",
      "34   35        Carlos Ramirez-Rosa           2710 NORTH SAWYER AVENUE  60647   \n",
      "35   36           Gilbert Villegas                 6934 WEST DIVERSEY  60607   \n",
      "36   37              Emma M. Mitts           4924 WEST CHICAGO AVENUE  60651   \n",
      "37   38           Nicholas Sposato          3821  NORTH HARLEM AVENUE  60634   \n",
      "38   39           Margaret Laurino          4404 WEST LAWRENCE AVENUE  60630   \n",
      "39   40        Patrick J. O'Connor          5850 NORTH LINCOLN AVENUE  60659   \n",
      "40   41      Anthony V. Napolitano           7442 NORTH HARLEM AVENUE  60631   \n",
      "41   42             Brendan Reilly   325 WEST HURON STREET, SUITE 510  60654   \n",
      "42   43             Michelle Smith          2523 NORTH HALSTED STREET  60614   \n",
      "43   44                 Tom Tunney        3223 NORTH SHEFFIELD AVENUE  60657   \n",
      "44   45              John S. Arena        4754 NORTH MILWAUKEE AVENUE  60630   \n",
      "45   46            James Cappleman         4544 NORTH BROADWAY AVENUE  60640   \n",
      "46   47                Ameya Pawar          4243 NORTH LINCOLN AVENUE  60618   \n",
      "47   48             Harry Osterman         5533 NORTH BROADWAY AVENUE  60640   \n",
      "48   49                  Joe Moore        7356 NORTH GREENVIEW AVENUE  60626   \n",
      "49   50       Debra L. Silverstein    2949 WEST DEVON AVENUE, SUITE A  60659   \n",
      "\n",
      "    pop_2000  pop_2010 change  \\\n",
      "0      52951     56149     6%   \n",
      "1      54361     55805     3%   \n",
      "2      40385     53039    31%   \n",
      "3      51953     54589     5%   \n",
      "4      55302     51455    -7%   \n",
      "5      54989     52341    -5%   \n",
      "6      54593     51581    -6%   \n",
      "7      54039     51687    -4%   \n",
      "8      52008     51519    -1%   \n",
      "9      56613     51535    -9%   \n",
      "10     64228     51497   -20%   \n",
      "11     68922     52235   -24%   \n",
      "12     64382     53722   -17%   \n",
      "13     80143     54031   -33%   \n",
      "14     56057     51501    -8%   \n",
      "15     50205     51954     3%   \n",
      "16     49264     51846     5%   \n",
      "17     55043     52992    -4%   \n",
      "18     54546     51525    -6%   \n",
      "19     51854     52372     1%   \n",
      "20     51751     51632     0%   \n",
      "21     59734     53515   -10%   \n",
      "22     63691     53728   -16%   \n",
      "23     50879     54909     8%   \n",
      "24     55954     54539    -3%   \n",
      "25     56841     53516    -6%   \n",
      "26     61287     52939   -14%   \n",
      "27     49423     55199    12%   \n",
      "28     61949     55267   -11%   \n",
      "29     72698     55560   -24%   \n",
      "30     65045     53724   -17%   \n",
      "31     57204     55184    -4%   \n",
      "32     63695     55598   -13%   \n",
      "33     49922     51599     3%   \n",
      "34     57588     55281    -4%   \n",
      "35     63376     54766   -14%   \n",
      "36     56120     51538    -8%   \n",
      "37     66011     56001   -15%   \n",
      "38     64291     55882   -13%   \n",
      "39     58652     55319    -6%   \n",
      "40     56127     55991     0%   \n",
      "41     68102     55870   -18%   \n",
      "42     57668     56170    -3%   \n",
      "43     58758     56058    -5%   \n",
      "44     60653     55967    -8%   \n",
      "45     56587     53784    -5%   \n",
      "46     52108     55074     6%   \n",
      "47     56246     55014    -2%   \n",
      "48     59435     54633    -8%   \n",
      "49     62383     55809   -11%   \n",
      "\n",
      "                                            address_y  zip_y  \n",
      "0                         2765 WEST SAINT MARY STREET  60647  \n",
      "1                            WM WASTE MANAGEMENT 1500  60622  \n",
      "2                                 17 EAST 38TH STREET  60653  \n",
      "3             31ST ST HARBOR BUILDING LAKEFRONT TRAIL  60653  \n",
      "4             JACKSON PARK LAGOON SOUTH CORNELL DRIVE  60637  \n",
      "5                                150 WEST 74TH STREET  60636  \n",
      "6                           8549 SOUTH OGLESBY AVENUE  60617  \n",
      "7                          1346-1352 EAST 75TH STREET  60649  \n",
      "8                  11039-11059 SOUTH WENTWORTH AVENUE  60628  \n",
      "9                                10534 SOUTH AVENUE F  46394  \n",
      "10                            943-947 WEST 14TH PLACE  60607  \n",
      "11                         CP 46 STEVENSON EXPRESSWAY  60632  \n",
      "12                    SOUTH RAMP SOUTH LARAMIE AVENUE  60638  \n",
      "13                              4540 WEST 51ST STREET  60632  \n",
      "14    CHICAGO FIRE DEPARTMENT ENGINE COMPANY 123 2215  60632  \n",
      "15                             6036 SOUTH WOOD STREET  60636  \n",
      "16                       7216 SOUTH WINCHESTER AVENUE  60636  \n",
      "17                          3286 WEST COLUMBUS AVENUE  60652  \n",
      "18                        9999 SOUTH FRANCISCO AVENUE  60805  \n",
      "19                     DAN RYAN EXPRESSWAY PARK MANOR  60621  \n",
      "20                     8852-8854 SOUTH EMERALD AVENUE  60620  \n",
      "21                              4233 WEST 36TH STREET  60632  \n",
      "22  CHICAGO MIDWAY INTERNATIONAL AIRPORT WEST 62ND...  60629  \n",
      "23                       1635 SOUTH CHRISTIANA AVENUE  60623  \n",
      "24                      1632-1746 SOUTH MILLER STREET  60608  \n",
      "25             LITTLE CUBS FIELD COMFORT STATION 1400  60622  \n",
      "26                      2151-2153 WEST CHICAGO AVENUE  60651  \n",
      "27                        RML SPECIALTY HOSPITAL 3435  60624  \n",
      "28                        1241 NORTH RIDGELAND AVENUE  60302  \n",
      "29                          5118 WEST FLETCHER STREET  60641  \n",
      "30                          2854 NORTH KEATING AVENUE  60641  \n",
      "31                        2901 NORTH WASHTENAW AVENUE  60618  \n",
      "32                    4041-4043 NORTH RICHMOND STREET  60625  \n",
      "33                    11544-11546 SOUTH PEORIA STREET  60827  \n",
      "34                           3634 WEST BELMONT AVENUE  60618  \n",
      "35                       2918 NORTH RUTHERFORD AVENUE  60634  \n",
      "36                         4738-4748 WEST RICE STREET  60651  \n",
      "37                    7307-7331 WEST IRVING PARK ROAD  60706  \n",
      "38                  QUEEN OF ALL SAINTS BASILICA 6280  60646  \n",
      "39                         5536 NORTH ARTESIAN AVENUE  60645  \n",
      "40                          1652 SOUTH CLIFTON AVENUE  60068  \n",
      "41                          410-420 WEST GRAND AVENUE  60654  \n",
      "42                              LINCOLN PARK ZOO 2001  60614  \n",
      "43                         507-513 WEST ALDINE AVENUE  60657  \n",
      "44       CONGREGATIONAL CHURCH OF JEFFERSON PARK 5320  60630  \n",
      "45                 UPTOWN BROADWAY BUILDING 4743-4763  60640  \n",
      "46                           2153 WEST BERTEAU AVENUE  60618  \n",
      "47                         1025 WEST HOLLYWOOD AVENUE  60660  \n",
      "48                             1426 WEST ESTES AVENUE  60645  \n",
      "49                       2638 WEST NORTH SHORE AVENUE  60645  \n"
     ]
    }
   ],
   "source": [
    "# Merge the wards and census tables on the ward column\n",
    "wards_census = wards.merge(census, on='ward')\n",
    "\n",
    "# Print the shape of wards_census\n",
    "print('wards_census table shape:', wards_census.shape)\n",
    "\n",
    "print(wards_census)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:20.055851Z",
     "start_time": "2024-01-06T05:11:19.968925Z"
    }
   },
   "id": "a7a33a5b530ed970",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instructions 2/3\n",
    "\n",
    "Merge the `wards_altered` and `census` tables on the `ward` column, and notice the difference in returned rows."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b36e7422cf0ac05"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ward\n",
      "0    61\n",
      "1     2\n",
      "2     3\n",
      "3     4\n",
      "4     5\n",
      "wards_altered_census table shape: (49, 9)\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'wards' and 'census' are your DataFrames\n",
    "\n",
    "# Create a copy of 'wards' DataFrame to perform alterations\n",
    "wards_altered = wards.copy()\n",
    "\n",
    "# Convert 'ward' column to integer type in 'wards_altered'\n",
    "wards_altered['ward'] = wards_altered['ward'].astype(int)\n",
    "\n",
    "# Add 60 to the first element in the 'ward' column in 'wards_altered'\n",
    "wards_altered.loc[0, 'ward'] += 60\n",
    "\n",
    "# Print the first few rows of the wards_altered table to view the change \n",
    "print(wards_altered[['ward']].head())\n",
    "\n",
    "# Check if 'ward' column in 'census' can be converted to integer type\n",
    "if census['ward'].astype(str).str.isdigit().all():\n",
    "    # Convert 'ward' column in 'census' to integer type\n",
    "    census['ward'] = census['ward'].astype(int)\n",
    "\n",
    "    # Merge the 'wards_altered' and 'census' tables on the 'ward' column\n",
    "    wards_altered_census = wards_altered.merge(census, on='ward')\n",
    "    print('wards_altered_census table shape:', wards_altered_census.shape)\n",
    "else:\n",
    "    print(\"Unable to convert 'ward' column in census DataFrame to integer type for merging.\")\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:20.163801Z",
     "start_time": "2024-01-06T05:11:19.996039Z"
    }
   },
   "id": "c0a9f34b85e8a63a",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instructions 3/3\n",
    "\n",
    "Merge the `wards` and `census_altered` tables on the `ward` column, and notice the difference in returned rows."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a792dec7f5088a8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ward\n",
      "0  None\n",
      "1     2\n",
      "2     3\n",
      "3     4\n",
      "4     5\n",
      "wards_census_altered table shape: (49, 4)\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'wards' and 'census' are your DataFrames\n",
    "\n",
    "# Create a copy of the first column of 'census' DataFrame and assign it to 'census_altered'\n",
    "census_altered = census.iloc[:, [0]].copy()\n",
    "\n",
    "# Set the 'ward' column to string type to allow for 'None' values\n",
    "census_altered['ward'] = census_altered['ward'].astype(str)\n",
    "\n",
    "# Set the first element in the 'ward' column to 'None'\n",
    "census_altered.loc[0, 'ward'] = 'None'\n",
    "\n",
    "# Convert 'ward' column in 'wards' to string type\n",
    "wards['ward'] = wards['ward'].astype(str)\n",
    "\n",
    "# Merge the 'wards' and 'census_altered' tables on the 'ward' column\n",
    "wards_census_altered = wards.merge(census_altered, on='ward')\n",
    "\n",
    "# Print the first few rows of the census_altered table to view the change \n",
    "print(census_altered[['ward']].head())\n",
    "\n",
    "# Print the shape of wards_census_altered\n",
    "print('wards_census_altered table shape:', wards_census_altered.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:20.185366Z",
     "start_time": "2024-01-06T05:11:20.009338Z"
    }
   },
   "id": "e0158d6454c2bd0d",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## One-to-many merge\n",
    "A business may have one or multiple owners. In this exercise, you will continue to gain experience with one-to-many merges by merging a table of business owners, called `biz_owners`, to the `licenses` table. Recall from the lesson, with a one-to-many relationship, a row in the left table may be repeated if it is related to multiple rows in the right table. In this lesson, you will explore this further by finding out what is the most common business owner title. (i.e., secretary, CEO, or vice president)\n",
    "\n",
    "The `licenses` and `biz_owners` DataFrames are loaded for you."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6eb479140dd542"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File opened successfully!\n",
      "  account ward  aid                   business               address    zip\n",
      "0  307071    3  743       REGGIE'S BAR & GRILL       2105 S STATE ST  60616\n",
      "1      10   10  829                 HONEYBEERS   13200 S HOUSTON AVE  60633\n",
      "2   10002   14  775                CELINA DELI     5089 S ARCHER AVE  60632\n",
      "3   10005   12  NaN  KRAFT FOODS NORTH AMERICA        2005 W 43RD ST  60609\n",
      "4   10044   44  638  NEYBOUR'S TAVERN & GRILLE  3651 N SOUTHPORT AVE  60613\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Navigate to the datasets folder\n",
    "datasets_directory = os.path.join(current_directory, '..', 'datasets')\n",
    "\n",
    "# Check if the file exists in the datasets folder\n",
    "file_path = os.path.join(datasets_directory, 'licenses.p')\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # File exists, so open it\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    # Work with the 'data' object as needed\n",
    "    print(\"File opened successfully!\")\n",
    "else:\n",
    "    print(\"File not found.\")\n",
    "licenses = data\n",
    "print(licenses.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:24.917040Z",
     "start_time": "2024-01-06T05:11:20.019250Z"
    }
   },
   "id": "8ffffea636e9b695",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File opened successfully!\n",
      "  account first_name  last_name      title\n",
      "0      10      PEARL    SHERMAN  PRESIDENT\n",
      "1      10      PEARL    SHERMAN  SECRETARY\n",
      "2   10002     WALTER     MROZEK    PARTNER\n",
      "3   10002     CELINA     BYRDAK    PARTNER\n",
      "4   10005      IRENE  ROSENFELD  PRESIDENT\n"
     ]
    }
   ],
   "source": [
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Navigate to the datasets folder\n",
    "datasets_directory = os.path.join(current_directory, '..', 'datasets')\n",
    "\n",
    "# Check if the file exists in the datasets folder\n",
    "file_path = os.path.join(datasets_directory, 'business_owners.p')\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # File exists, so open it\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    # Work with the 'data' object as needed\n",
    "    print(\"File opened successfully!\")\n",
    "else:\n",
    "    print(\"File not found.\")\n",
    "biz_owners = data\n",
    "\n",
    "print(biz_owners.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:28.595203Z",
     "start_time": "2024-01-06T05:11:24.924124Z"
    }
   },
   "id": "12c4b449a2321279",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instructions\n",
    "\n",
    "- Starting with the `licenses` table on the left, merge it to the `biz_owners` table on the column `account`, and save the results to a variable named `licenses_owners`.\n",
    "- Group `licenses_owners` by `title` and count the number of accounts for each title. Save the result as `counted_df`\n",
    "- Sort `counted_df` by the number of ***accounts*** in ***descending order***, and save this as a variable named `sorted_df`.\n",
    "- Use the `.head()` method to print the first few rows of the `sorted_df`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c05c6310d4864028"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 account\n",
      "title                   \n",
      "PRESIDENT           6259\n",
      "SECRETARY           5205\n",
      "SOLE PROPRIETOR     1658\n",
      "OTHER               1200\n",
      "VICE PRESIDENT       970\n"
     ]
    }
   ],
   "source": [
    "# Merge the licenses and biz_owners table on account\n",
    "licenses_owners = licenses.merge(biz_owners, on='account')\n",
    "\n",
    "# Group the results by title then count the number of accounts\n",
    "counted_df = licenses_owners.groupby('title').agg({'account':'count'})\n",
    "\n",
    "# Sort the counted_df in desending order\n",
    "sorted_df = counted_df.sort_values(by='account', ascending = False)\n",
    "\n",
    "# Use .head() method to print the first few rows of sorted_df\n",
    "print(sorted_df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:28.680286Z",
     "start_time": "2024-01-06T05:11:28.610605Z"
    }
   },
   "id": "2e73d411abbc9735",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Total riders in a month\n",
    "Your goal is to find the total number of rides provided to passengers passing through the Wilson station (`station_name == 'Wilson'`) when riding Chicago's public transportation system on weekdays (`day_type == 'Weekday'`) in July (month == 7). Luckily, Chicago provides this detailed data, but it is in three different tables. You will work on merging these tables together to answer the question. This data is different from the business related data you have seen so far, but all the information you need to answer the question is provided.\n",
    "\n",
    "The `cal`, `ridership`, and `stations` DataFrames have been loaded for you. The relationship between the tables can be seen in the diagram below."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcc48e14ae6a900d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![The relationship between the tables](../datasets/cta_L_diagram.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f26f74b410d43802"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File opened successfully!\n",
      "   year  month  day        day_type\n",
      "0  2019      1    1  Sunday/Holiday\n",
      "1  2019      1    2         Weekday\n",
      "2  2019      1    3         Weekday\n",
      "3  2019      1    4         Weekday\n",
      "4  2019      1    5        Saturday\n"
     ]
    }
   ],
   "source": [
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Navigate to the datasets folder\n",
    "datasets_directory = os.path.join(current_directory, '..', 'datasets')\n",
    "\n",
    "# Check if the file exists in the datasets folder\n",
    "file_path = os.path.join(datasets_directory, 'cta_calendar.p')\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # File exists, so open it\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    # Work with the 'data' object as needed\n",
    "    print(\"File opened successfully!\")\n",
    "else:\n",
    "    print(\"File not found.\")\n",
    "cal = data\n",
    "\n",
    "print(cal.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:28.800127Z",
     "start_time": "2024-01-06T05:11:28.643216Z"
    }
   },
   "id": "e64a58e353590530",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File opened successfully!\n",
      "  station_id  year  month  day  rides\n",
      "0      40010  2019      1    1    576\n",
      "1      40010  2019      1    2   1457\n",
      "2      40010  2019      1    3   1543\n",
      "3      40010  2019      1    4   1621\n",
      "4      40010  2019      1    5    719\n"
     ]
    }
   ],
   "source": [
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Navigate to the datasets folder\n",
    "datasets_directory = os.path.join(current_directory, '..', 'datasets')\n",
    "\n",
    "# Check if the file exists in the datasets folder\n",
    "file_path = os.path.join(datasets_directory, 'cta_ridership.p')\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # File exists, so open it\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    # Work with the 'data' object as needed\n",
    "    print(\"File opened successfully!\")\n",
    "else:\n",
    "    print(\"File not found.\")\n",
    "ridership = data\n",
    "\n",
    "print(ridership.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:29.194331Z",
     "start_time": "2024-01-06T05:11:28.798900Z"
    }
   },
   "id": "40df06f7f411f847",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File opened successfully!\n",
      "  station_id        station_name                 location\n",
      "0      40010  Austin-Forest Park  (41.870851, -87.776812)\n",
      "1      40020         Harlem-Lake  (41.886848, -87.803176)\n",
      "2      40030        Pulaski-Lake  (41.885412, -87.725404)\n",
      "3      40040        Quincy/Wells   (41.878723, -87.63374)\n",
      "4      40050               Davis   (42.04771, -87.683543)\n"
     ]
    }
   ],
   "source": [
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Navigate to the datasets folder\n",
    "datasets_directory = os.path.join(current_directory, '..', 'datasets')\n",
    "\n",
    "# Check if the file exists in the datasets folder\n",
    "file_path = os.path.join(datasets_directory, 'stations.p')\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # File exists, so open it\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    # Work with the 'data' object as needed\n",
    "    print(\"File opened successfully!\")\n",
    "else:\n",
    "    print(\"File not found.\")\n",
    "stations = data\n",
    "\n",
    "print(stations.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:29.358140Z",
     "start_time": "2024-01-06T05:11:29.196342Z"
    }
   },
   "id": "f9435b27ca2a7346",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instructions 1/3\n",
    "\n",
    "Merge the `ridership` and `cal` tables together, starting with the `ridership` table on the left and save the result to the variable `ridership_cal`. If you code takes too long to run, your merge conditions might be incorrect."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c985aff2e8cc3f6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Merge the ridership and cal tables\n",
    "ridership_cal = ridership.merge(cal)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:29.368178Z",
     "start_time": "2024-01-06T05:11:29.360239Z"
    }
   },
   "id": "d1875ab33763d9bb",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instructions 2/3\n",
    "\n",
    "Extend the previous merge to three tables by also merging the `stations` table."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c52fbcf9e6bd0215"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     station_id  year  month  day  rides        day_type        station_name  \\\n",
      "0         40010  2019      1    1    576  Sunday/Holiday  Austin-Forest Park   \n",
      "1         40010  2019      1    2   1457         Weekday  Austin-Forest Park   \n",
      "2         40010  2019      1    3   1543         Weekday  Austin-Forest Park   \n",
      "3         40010  2019      1    4   1621         Weekday  Austin-Forest Park   \n",
      "4         40010  2019      1    5    719        Saturday  Austin-Forest Park   \n",
      "...         ...   ...    ...  ...    ...             ...                 ...   \n",
      "3280      41660  2019     12   27  13898         Weekday          Lake/State   \n",
      "3281      41660  2019     12   28   9485        Saturday          Lake/State   \n",
      "3282      41660  2019     12   29   7581  Sunday/Holiday          Lake/State   \n",
      "3283      41660  2019     12   30  15332         Weekday          Lake/State   \n",
      "3284      41660  2019     12   31  13430         Weekday          Lake/State   \n",
      "\n",
      "                     location  \n",
      "0     (41.870851, -87.776812)  \n",
      "1     (41.870851, -87.776812)  \n",
      "2     (41.870851, -87.776812)  \n",
      "3     (41.870851, -87.776812)  \n",
      "4     (41.870851, -87.776812)  \n",
      "...                       ...  \n",
      "3280  (41.884809, -87.627813)  \n",
      "3281  (41.884809, -87.627813)  \n",
      "3282  (41.884809, -87.627813)  \n",
      "3283  (41.884809, -87.627813)  \n",
      "3284  (41.884809, -87.627813)  \n",
      "\n",
      "[3285 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge the ridership, cal, and stations tables\n",
    "ridership_cal_stations = ridership.merge(cal, on=['year','month','day']) \\\n",
    "    .merge(stations, on=['station_id'])\n",
    "\n",
    "print(ridership_cal_stations)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:29.422114Z",
     "start_time": "2024-01-06T05:11:29.372030Z"
    }
   },
   "id": "cd2600801ec59957",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instructions 3/3\n",
    "\n",
    "Create a variable called `filter_criteria` to select the appropriate rows from the merged table so that you can sum the `rides` column."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b27e08a2a9ddcfa6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140005\n"
     ]
    }
   ],
   "source": [
    "# Merge the ridership, cal, and stations tables\n",
    "ridership_cal_stations = ridership.merge(cal, on=['year','month','day']) \\\n",
    "    .merge(stations, on='station_id')\n",
    "\n",
    "# Create a filter to filter ridership_cal_stations\n",
    "filter_criteria = ((ridership_cal_stations['month'] == 7)\n",
    "                   & (ridership_cal_stations['day_type'] == 'Weekday')\n",
    "                   & (ridership_cal_stations['station_name'] == 'Wilson'))\n",
    "\n",
    "# Use .loc and the filter to select for rides\n",
    "print(ridership_cal_stations.loc[filter_criteria, 'rides'].sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:29.425066Z",
     "start_time": "2024-01-06T05:11:29.391109Z"
    }
   },
   "id": "63f83547bfe7e94e",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Three table merge\n",
    "To solidify the concept of a three DataFrame merge, practice another exercise. A reasonable extension of our review of Chicago business data would include looking at demographics information about the neighborhoods where the businesses are. A table with the median income by zip code has been provided to you. You will merge the licenses and wards tables with this new income-by-zip-code table called zip_demo.\n",
    "\n",
    "The `licenses`, `wards`, and `zip_demo` DataFrames have been loaded for you."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e0ce80bb6b6d263"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File opened successfully!\n",
      "     zip  income\n",
      "0  60630   70122\n",
      "1  60640   50488\n",
      "2  60622   87143\n",
      "3  60614  100116\n",
      "4  60608   41226\n"
     ]
    }
   ],
   "source": [
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Navigate to the datasets folder\n",
    "datasets_directory = os.path.join(current_directory, '..', 'datasets')\n",
    "\n",
    "# Check if the file exists in the datasets folder\n",
    "file_path = os.path.join(datasets_directory, 'zip_demo.p')\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # File exists, so open it\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    # Work with the 'data' object as needed\n",
    "    print(\"File opened successfully!\")\n",
    "else:\n",
    "    print(\"File not found.\")\n",
    "zip_demo = data\n",
    "\n",
    "print(zip_demo.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:29.626687Z",
     "start_time": "2024-01-06T05:11:29.407628Z"
    }
   },
   "id": "59cac944c47f42",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             income\n",
      "alderman                           \n",
      "Ameya Pawar                 66246.0\n",
      "Anthony A. Beale            38206.0\n",
      "Anthony V. Napolitano       82226.0\n",
      "Ariel E. Reyboras           41307.0\n",
      "Brendan Reilly             110215.0\n",
      "Brian Hopkins               87143.0\n",
      "Carlos Ramirez-Rosa         66246.0\n",
      "Carrie M. Austin            38206.0\n",
      "Chris Taliaferro            55566.0\n",
      "Daniel \"Danny\" Solis        41226.0\n",
      "David H. Moore              33304.0\n",
      "Deborah Mell                66246.0\n",
      "Debra L. Silverstein        50554.0\n",
      "Derrick G. Curtis           65770.0\n",
      "Edward M. Burke             42335.0\n",
      "Emma M. Mitts               36283.0\n",
      "George Cardenas             33959.0\n",
      "Gilbert Villegas            41307.0\n",
      "Gregory I. Mitchell         24941.0\n",
      "Harry Osterman              45442.0\n",
      "Howard B. Brookins, Jr.     33304.0\n",
      "James Cappleman             79565.0\n",
      "Jason C. Ervin              41226.0\n",
      "Joe Moore                   39163.0\n",
      "John S. Arena               70122.0\n",
      "Leslie A. Hairston          28024.0\n",
      "Margaret Laurino            70122.0\n",
      "Marty Quinn                 67045.0\n",
      "Matthew J. O'Shea           59488.0\n",
      "Michael R. Zalewski         42335.0\n",
      "Michael Scott, Jr.          31445.0\n",
      "Michelle A. Harris          32558.0\n",
      "Michelle Smith             100116.0\n",
      "Milagros \"Milly\" Santiago   41307.0\n",
      "Nicholas Sposato            62223.0\n",
      "Pat Dowell                  46340.0\n",
      "Patrick Daley Thompson      41226.0\n",
      "Patrick J. O'Connor         50554.0\n",
      "Proco \"Joe\" Moreno          87143.0\n",
      "Raymond A. Lopez            33959.0\n",
      "Ricardo Munoz               31445.0\n",
      "Roberto Maldonado           68223.0\n",
      "Roderick T. Sawyer          32558.0\n",
      "Scott Waguespack            68223.0\n",
      "Susan Sadlowski Garza       38417.0\n",
      "Tom Tunney                  88708.0\n",
      "Toni L. Foulkes             27573.0\n",
      "Walter Burnett, Jr.         87143.0\n",
      "William D. Burns           107811.0\n",
      "Willie B. Cochran           28024.0\n"
     ]
    }
   ],
   "source": [
    "# Merge licenses and zip_demo, on zip; and merge the wards on ward\n",
    "licenses_zip_ward = licenses.merge(zip_demo, on=['zip']) \\\n",
    "    .merge(wards, on=['ward']) \n",
    "\n",
    "# Print the results by alderman and show median income\n",
    "print(licenses_zip_ward.groupby('alderman').agg({'income':'median'}))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:29.686934Z",
     "start_time": "2024-01-06T05:11:29.630872Z"
    }
   },
   "id": "d2d86db21c76c1fc",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fcaefd50207b763c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## One-to-many merge with multiple tables\n",
    "In this exercise, assume that you are looking to start a business in the city of Chicago. Your perfect idea is to start a company that uses goats to mow the lawn for other businesses. However, you have to choose a location in the city to put your goat farm. You need a location with a great deal of space and relatively few businesses and people around to avoid complaints about the smell. You will need to merge three tables to help you choose your location. The land_use table has info on the percentage of vacant land by city ward. The census table has population by ward, and the licenses table lists businesses by ward.\n",
    "\n",
    "The `land_use`, census, and `licenses` tables have been loaded for you."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9eccafdc96d963c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File opened successfully!\n",
      "  ward  residential  commercial  industrial  vacant  other\n",
      "0    1           41           9           2       2     46\n",
      "1    2           31          11           6       2     50\n",
      "2    3           20           5           3      13     59\n",
      "3    4           22          13           0       7     58\n",
      "4    5           25           3           1       3     68\n"
     ]
    }
   ],
   "source": [
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Navigate to the datasets folder\n",
    "datasets_directory = os.path.join(current_directory, '..', 'datasets')\n",
    "\n",
    "# Check if the file exists in the datasets folder\n",
    "file_path = os.path.join(datasets_directory, 'land_use.p')\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # File exists, so open it\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    # Work with the 'data' object as needed\n",
    "    print(\"File opened successfully!\")\n",
    "else:\n",
    "    print(\"File not found.\")\n",
    "land_use = data\n",
    "\n",
    "print(land_use.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:29.773561Z",
     "start_time": "2024-01-06T05:11:29.659619Z"
    }
   },
   "id": "2f4d62ad0aaa674",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instructions 1/3\n",
    "\n",
    "Merge `land_use` and `census` on the `ward` column. Merge the result of this with `licenses` on the `ward` column, using the suffix `_cen` for the left table and `_lic` for the right table. Save this to the variable `land_cen_lic`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6601b1d146385173"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Convert the 'ward' column in the land_use DataFrame to the same data type as other DataFrames\n",
    "land_use['ward'] = land_use['ward'].astype(int)\n",
    "\n",
    "# Merge land_use and census on the ward column\n",
    "merged_data = pd.merge(land_use, census, on='ward')\n",
    "\n",
    "# Convert the 'ward' column in the licenses DataFrame to the same data type\n",
    "licenses['ward'] = licenses['ward'].astype(int)\n",
    "\n",
    "# Merge merged_data and licenses on the ward column, providing suffixes for clarity\n",
    "land_cen_lic = pd.merge(merged_data, licenses, on='ward', suffixes=('_cen', '_lic'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:21:58.698283Z",
     "start_time": "2024-01-06T05:21:58.668430Z"
    }
   },
   "id": "a290a04fdfbb6b7c",
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instructions 2/3\n",
    "\n",
    "Group `land_cen_lic` by `ward`, `pop_2010` (the population in 2010), and `vacant`, then count the number of `accounts`. Save the results to pop_vac_lic."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "924ee0c50a72b257"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Group by ward, pop_2010, and vacant, then count the # of accounts\n",
    "pop_vac_lic = land_cen_lic.groupby(['ward','pop_2010', 'vacant'],\n",
    "                                   as_index=False).agg({'account':'count'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:24:09.716394Z",
     "start_time": "2024-01-06T05:24:09.684796Z"
    }
   },
   "id": "fc5b4418d0185aa9",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instructions 3/3\n",
    "\n",
    "Sort `pop_vac_lic` by `vacant`, `account`, and `pop_2010` in descending, ascending, and ascending order respectively. Save it as `sorted_pop_vac_lic`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa2abf8053a1a0d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ward  pop_2010  vacant  account\n",
      "6      7     51581      19       80\n",
      "19    20     52372      15      123\n",
      "9     10     51535      14      130\n",
      "23    24     54909      13       98\n",
      "15    16     51954      13      156\n"
     ]
    }
   ],
   "source": [
    "# Sort pop_vac_lic and print the results\n",
    "sorted_pop_vac_lic = pop_vac_lic.sort_values(by=['vacant', 'account', 'pop_2010'],\n",
    "                                             ascending=[False, True, True])\n",
    "\n",
    "# Print the top few rows of sorted_pop_vac_lic\n",
    "print(sorted_pop_vac_lic.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T05:24:12.007434Z",
     "start_time": "2024-01-06T05:24:11.972511Z"
    }
   },
   "id": "1f3ae74b6446a7c4",
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
