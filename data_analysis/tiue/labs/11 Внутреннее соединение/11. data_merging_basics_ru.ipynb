{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d702867a9407cf90",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Объединение данных с помощью pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3296083285a187eb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Основы объединения данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:19.277417Z",
     "start_time": "2024-01-06T05:11:15.636570Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл успешно открыт!\n"
     ]
    }
   ],
   "source": [
    "# Предполагая, что ваш блокнот Jupyter находится в папке exercises\n",
    "# Вы хотите получить доступ к файлу taxi_owners.p в папке datasets\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Получить текущую директорию\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Перейти в папку datasets\n",
    "datasets_directory = os.path.join(current_directory, 'datasets')\n",
    "\n",
    "# Проверить, существует ли файл в папке datasets\n",
    "file_path = os.path.join(datasets_directory, 'taxi_owners.p')\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # Файл существует, поэтому откройте его\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    # Работайте с объектом 'data' по необходимости\n",
    "    print(\"Файл успешно открыт!\")\n",
    "else:\n",
    "    print(\"Файл не найден.\")\n",
    "taxi_owners = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c49901c944eadfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:19.404907Z",
     "start_time": "2024-01-06T05:11:19.308499Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл успешно открыт!\n"
     ]
    }
   ],
   "source": [
    "# Получить текущую директорию\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Перейти в папку datasets\n",
    "datasets_directory = os.path.join(current_directory, 'datasets')\n",
    "\n",
    "# Проверить, существует ли файл в папке datasets\n",
    "file_path = os.path.join(datasets_directory, 'taxi_vehicles.p')\n",
    "\n",
    "try:\n",
    "    if os.path.exists(file_path):\n",
    "        # Файл существует, поэтому откройте его\n",
    "        with open(file_path, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "        # Работайте с объектом 'data' по необходимости\n",
    "        print(\"Файл успешно открыт!\")\n",
    "        taxi_vehicles = data\n",
    "    else:\n",
    "        print(\"Файл не найден.\")\n",
    "except Exception as e:\n",
    "    print(f\"Произошла ошибка: {e}\")\n",
    "    taxi_vehicles = None  # Присваивание None 'taxi_vehicles', если произошла ошибка\n",
    "\n",
    "taxi_veh = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb38e431ad6dd830",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Ваше первое внутреннее соединение\n",
    "\n",
    "Вам предстоит выяснить, какие виды топлива наиболее популярны в такси Чикаго. Чтобы завершить анализ, вам необходимо объединить таблицы `«taxi_owners»` и `«taxi_veh»` в столбце `«vid»`. Затем вы можете использовать объединенную таблицу вместе с методом `.value_counts()`, чтобы найти наиболее распространенный тип `Fuel_type`.\n",
    "\n",
    "Поскольку на протяжении всего курса вы будете работать с pandas, пакет будет предварительно загружен для вас как pd в каждом упражнении этого курса. Также для вас загружаются DataFrames `taxi_owners` и `taxi_veh`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0655f543c5659c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Инструкции 1/3\n",
    "\n",
    "1. Объедините `«taxi_owners»` с `«taxi_veh»` в столбце `«vid»` и сохраните результат в `«taxi_own_veh»`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fb0598bb0384d8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:19.526941Z",
     "start_time": "2024-01-06T05:11:19.340620Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rid', 'vid', 'owner_x', 'address', 'zip', 'make', 'model', 'year',\n",
      "       'fuel_type', 'owner_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Объединить таблицы taxi_owners и taxi_veh\n",
    "taxi_own_veh = taxi_owners.merge(taxi_veh, on='vid')\n",
    "\n",
    "# Вывести названия столбцов в taxi_own_veh\n",
    "print(taxi_own_veh.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36699a12d6a5d194",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Инструкции 2/3\n",
    "\n",
    "Установите суффиксы левой и правой таблицы для перекрывающихся столбцов слияния на `_own` и `_veh` соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8c492c719dfacbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:19.530097Z",
     "start_time": "2024-01-06T05:11:19.361834Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rid', 'vid', 'owner_own', 'address', 'zip', 'make', 'model', 'year',\n",
      "       'fuel_type', 'owner_veh'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Объединить таблицы taxi_owners и taxi_veh, установив суффиксы\n",
    "taxi_own_veh = taxi_owners.merge(taxi_veh, on='vid', suffixes=('_own', '_veh'))\n",
    "\n",
    "# Вывести названия столбцов в taxi_own_veh\n",
    "print(taxi_own_veh.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a007f0cc0220a4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Инструкции 3/3\n",
    "\n",
    "Выберите столбец `«fuel_type»` из `«taxi_own_veh»` и распечатайте `«value_counts()»`, чтобы найти наиболее популярные используемые `«fuel_types»`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e19177dd9c8d5f1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:19.548475Z",
     "start_time": "2024-01-06T05:11:19.373684Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYBRID                    2792\n",
      "GASOLINE                   611\n",
      "FLEX FUEL                   89\n",
      "COMPRESSED NATURAL GAS      27\n",
      "Name: fuel_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Объединить таблицы taxi_owners и taxi_veh, установив суффиксы\n",
    "taxi_own_veh = taxi_owners.merge(taxi_veh, on='vid', suffixes=('_own', '_veh'))\n",
    "\n",
    "# Вывести value_counts, чтобы найти наиболее популярный тип топлива\n",
    "print(taxi_own_veh['fuel_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ba1034993f99348",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:19.883328Z",
     "start_time": "2024-01-06T05:11:19.389599Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл 'ward.p' открыт и сохранен в DataFrame 'wards'.\n",
      "   ward                   alderman                            address    zip\n",
      "0     1         Proco \"Joe\" Moreno          2058 NORTH WESTERN AVENUE  60647\n",
      "1     2              Brian Hopkins         1400 NORTH  ASHLAND AVENUE  60622\n",
      "2     3                 Pat Dowell            5046 SOUTH STATE STREET  60609\n",
      "3     4           William D. Burns    435 EAST 35TH STREET, 1ST FLOOR  60616\n",
      "4     5         Leslie A. Hairston              2325 EAST 71ST STREET  60649\n",
      "5     6         Roderick T. Sawyer   8001 S. MARTIN LUTHER KING DRIVE  60619\n",
      "6     7        Gregory I. Mitchell              2249 EAST 95TH STREET  60617\n",
      "7     8         Michelle A. Harris    8539 SOUTH COTTAGE GROVE AVENUE  60619\n",
      "8     9           Anthony A. Beale                34 EAST 112TH PLACE  60628\n",
      "9    10      Susan Sadlowski Garza           10500 SOUTH EWING AVENUE  60617\n",
      "10   11     Patrick Daley Thompson          3659 SOUTH HALSTED STREET  60609\n",
      "11   12            George Cardenas           3476 SOUTH ARCHER AVENUE  60608\n",
      "12   13                Marty Quinn            6500 SOUTH PULASKI ROAD  60629\n",
      "13   14            Edward M. Burke              2650 WEST 51ST STREET  60632\n",
      "14   15           Raymond A. Lopez              1650 WEST 63RD STREET  60636\n",
      "15   16            Toni L. Foulkes              3045 WEST 63RD STREET  60629\n",
      "16   17             David H. Moore          7313 SOUTH ASHLAND AVENUE  60636\n",
      "17   18          Derrick G. Curtis            8359 SOUTH PULASKI ROAD  60652\n",
      "18   19          Matthew J. O'Shea         10400 SOUTH WESTERN AVENUE  60643\n",
      "19   20          Willie B. Cochran    6357 SOUTH COTTAGE GROVE AVENUE  60637\n",
      "20   21    Howard B. Brookins, Jr.  9011 SOUTH ASHLAND AVENUE, UNIT B  60620\n",
      "21   22              Ricardo Munoz        2500 SOUTH ST. LOUIS AVENUE  60623\n",
      "22   23        Michael R. Zalewski           6247 SOUTH ARCHER AVENUE  60638\n",
      "23   24         Michael Scott, Jr.           1158 SOUTH KEELER AVENUE  60624\n",
      "24   25       Daniel \"Danny\" Solis      1800 SOUTH BLUE ISLAND AVENUE  60608\n",
      "25   26          Roberto Maldonado          2511 WEST DIVISION STREET  60622\n",
      "26   27        Walter Burnett, Jr.             4 NORTH WESTERN AVENUE  60612\n",
      "27   28             Jason C. Ervin              2602 WEST 16TH STREET  60612\n",
      "28   29           Chris Taliaferro             6272 WEST NORTH AVENUE  60639\n",
      "29   30          Ariel E. Reyboras        3559 NORTH MILWAUKEE AVENUE  60641\n",
      "30   31  Milagros \"Milly\" Santiago            2521 NORTH PULASKI ROAD  60639\n",
      "31   32           Scott Waguespack         2657 NORTH CLYBOURN AVENUE  60614\n",
      "32   33               Deborah Mell         3001 WEST IRVING PARK ROAD  60618\n",
      "33   34           Carrie M. Austin              507 WEST 111TH STREET  60628\n",
      "34   35        Carlos Ramirez-Rosa           2710 NORTH SAWYER AVENUE  60647\n",
      "35   36           Gilbert Villegas                 6934 WEST DIVERSEY  60607\n",
      "36   37              Emma M. Mitts           4924 WEST CHICAGO AVENUE  60651\n",
      "37   38           Nicholas Sposato          3821  NORTH HARLEM AVENUE  60634\n",
      "38   39           Margaret Laurino          4404 WEST LAWRENCE AVENUE  60630\n",
      "39   40        Patrick J. O'Connor          5850 NORTH LINCOLN AVENUE  60659\n",
      "40   41      Anthony V. Napolitano           7442 NORTH HARLEM AVENUE  60631\n",
      "41   42             Brendan Reilly   325 WEST HURON STREET, SUITE 510  60654\n",
      "42   43             Michelle Smith          2523 NORTH HALSTED STREET  60614\n",
      "43   44                 Tom Tunney        3223 NORTH SHEFFIELD AVENUE  60657\n",
      "44   45              John S. Arena        4754 NORTH MILWAUKEE AVENUE  60630\n",
      "45   46            James Cappleman         4544 NORTH BROADWAY AVENUE  60640\n",
      "46   47                Ameya Pawar          4243 NORTH LINCOLN AVENUE  60618\n",
      "47   48             Harry Osterman         5533 NORTH BROADWAY AVENUE  60640\n",
      "48   49                  Joe Moore        7356 NORTH GREENVIEW AVENUE  60626\n",
      "49   50       Debra L. Silverstein    2949 WEST DEVON AVENUE, SUITE A  60659\n"
     ]
    }
   ],
   "source": [
    "# Путь к файлу wards.p\n",
    "ward_file_path = os.path.join(datasets_directory, 'ward.p')\n",
    "\n",
    "# Загрузить wards.p, если он существует, как DataFrame с именем 'wards'\n",
    "if os.path.exists(ward_file_path):\n",
    "    with open(ward_file_path, 'rb') as file:\n",
    "        wards = pd.DataFrame(pickle.load(file))\n",
    "        print(\"Файл 'ward.p' открыт и сохранен в DataFrame 'wards'.\")\n",
    "else:\n",
    "    print(\"Файл 'ward.p' не найден.\")\n",
    "\n",
    "print(wards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20e43eee91d93dee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:20.044588Z",
     "start_time": "2024-01-06T05:11:19.676307Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл 'census.p' открыт и сохранен в DataFrame 'census'.\n",
      "  ward  pop_2000  pop_2010 change                                  address  \\\n",
      "0    1     52951     56149     6%              2765 WEST SAINT MARY STREET   \n",
      "1    2     54361     55805     3%                 WM WASTE MANAGEMENT 1500   \n",
      "2    3     40385     53039    31%                      17 EAST 38TH STREET   \n",
      "3    4     51953     54589     5%  31ST ST HARBOR BUILDING LAKEFRONT TRAIL   \n",
      "4    5     55302     51455    -7%  JACKSON PARK LAGOON SOUTH CORNELL DRIVE   \n",
      "\n",
      "     zip  \n",
      "0  60647  \n",
      "1  60622  \n",
      "2  60653  \n",
      "3  60653  \n",
      "4  60637  \n"
     ]
    }
   ],
   "source": [
    "# Путь к файлу census.p\n",
    "census_file_path = os.path.join(datasets_directory, 'census.p')\n",
    "\n",
    "# Загрузить census.p, если он существует, как DataFrame с именем 'census'\n",
    "if os.path.exists(census_file_path):\n",
    "    with open(census_file_path, 'rb') as file:\n",
    "        census = pd.DataFrame(pickle.load(file))\n",
    "        print(\"Файл 'census.p' открыт и сохранен в DataFrame 'census'.\")\n",
    "else:\n",
    "    print(\"Файл 'census.p' не найден.\")\n",
    "\n",
    "print(census.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d988cf250f16769",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Внутренние соединения и количество возвращаемых строк\n",
    "\n",
    "Все слияния, которые вы изучили до этого момента, называются внутренними соединениями. Необходимо понимать, что внутренние соединения возвращают только строки с совпадающими значениями в обеих таблицах. Вы исследуете это дальше, рассмотрев слияние таблиц «wards» и «census», а затем сравнив его со слиянием слегка измененных копий этих таблиц, названных `«wards_altered»` и `«census_altered»`. В измененных таблицах изменена первая строка столбца подопечных. Вы увидите, как это влияет на слияние между ними. Таблицы для вас загружены.\n",
    "\n",
    "Для этого упражнения важно знать, что таблицы `«wards»` и `census` начинаются с 50 строк."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65063119c863a2e4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Инструкции 1/3\n",
    "\n",
    "Объедините значения `«wards»` и `«census»` в столбце `«ward»` и сохраните результат в столбце `«wards_census»`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7a33a5b530ed970",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:20.055851Z",
     "start_time": "2024-01-06T05:11:19.968925Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма таблицы wards_census: (50, 9)\n",
      "   ward                   alderman                          address_x  zip_x  \\\n",
      "0     1         Proco \"Joe\" Moreno          2058 NORTH WESTERN AVENUE  60647   \n",
      "1     2              Brian Hopkins         1400 NORTH  ASHLAND AVENUE  60622   \n",
      "2     3                 Pat Dowell            5046 SOUTH STATE STREET  60609   \n",
      "3     4           William D. Burns    435 EAST 35TH STREET, 1ST FLOOR  60616   \n",
      "4     5         Leslie A. Hairston              2325 EAST 71ST STREET  60649   \n",
      "5     6         Roderick T. Sawyer   8001 S. MARTIN LUTHER KING DRIVE  60619   \n",
      "6     7        Gregory I. Mitchell              2249 EAST 95TH STREET  60617   \n",
      "7     8         Michelle A. Harris    8539 SOUTH COTTAGE GROVE AVENUE  60619   \n",
      "8     9           Anthony A. Beale                34 EAST 112TH PLACE  60628   \n",
      "9    10      Susan Sadlowski Garza           10500 SOUTH EWING AVENUE  60617   \n",
      "10   11     Patrick Daley Thompson          3659 SOUTH HALSTED STREET  60609   \n",
      "11   12            George Cardenas           3476 SOUTH ARCHER AVENUE  60608   \n",
      "12   13                Marty Quinn            6500 SOUTH PULASKI ROAD  60629   \n",
      "13   14            Edward M. Burke              2650 WEST 51ST STREET  60632   \n",
      "14   15           Raymond A. Lopez              1650 WEST 63RD STREET  60636   \n",
      "15   16            Toni L. Foulkes              3045 WEST 63RD STREET  60629   \n",
      "16   17             David H. Moore          7313 SOUTH ASHLAND AVENUE  60636   \n",
      "17   18          Derrick G. Curtis            8359 SOUTH PULASKI ROAD  60652   \n",
      "18   19          Matthew J. O'Shea         10400 SOUTH WESTERN AVENUE  60643   \n",
      "19   20          Willie B. Cochran    6357 SOUTH COTTAGE GROVE AVENUE  60637   \n",
      "20   21    Howard B. Brookins, Jr.  9011 SOUTH ASHLAND AVENUE, UNIT B  60620   \n",
      "21   22              Ricardo Munoz        2500 SOUTH ST. LOUIS AVENUE  60623   \n",
      "22   23        Michael R. Zalewski           6247 SOUTH ARCHER AVENUE  60638   \n",
      "23   24         Michael Scott, Jr.           1158 SOUTH KEELER AVENUE  60624   \n",
      "24   25       Daniel \"Danny\" Solis      1800 SOUTH BLUE ISLAND AVENUE  60608   \n",
      "25   26          Roberto Maldonado          2511 WEST DIVISION STREET  60622   \n",
      "26   27        Walter Burnett, Jr.             4 NORTH WESTERN AVENUE  60612   \n",
      "27   28             Jason C. Ervin              2602 WEST 16TH STREET  60612   \n",
      "28   29           Chris Taliaferro             6272 WEST NORTH AVENUE  60639   \n",
      "29   30          Ariel E. Reyboras        3559 NORTH MILWAUKEE AVENUE  60641   \n",
      "30   31  Milagros \"Milly\" Santiago            2521 NORTH PULASKI ROAD  60639   \n",
      "31   32           Scott Waguespack         2657 NORTH CLYBOURN AVENUE  60614   \n",
      "32   33               Deborah Mell         3001 WEST IRVING PARK ROAD  60618   \n",
      "33   34           Carrie M. Austin              507 WEST 111TH STREET  60628   \n",
      "34   35        Carlos Ramirez-Rosa           2710 NORTH SAWYER AVENUE  60647   \n",
      "35   36           Gilbert Villegas                 6934 WEST DIVERSEY  60607   \n",
      "36   37              Emma M. Mitts           4924 WEST CHICAGO AVENUE  60651   \n",
      "37   38           Nicholas Sposato          3821  NORTH HARLEM AVENUE  60634   \n",
      "38   39           Margaret Laurino          4404 WEST LAWRENCE AVENUE  60630   \n",
      "39   40        Patrick J. O'Connor          5850 NORTH LINCOLN AVENUE  60659   \n",
      "40   41      Anthony V. Napolitano           7442 NORTH HARLEM AVENUE  60631   \n",
      "41   42             Brendan Reilly   325 WEST HURON STREET, SUITE 510  60654   \n",
      "42   43             Michelle Smith          2523 NORTH HALSTED STREET  60614   \n",
      "43   44                 Tom Tunney        3223 NORTH SHEFFIELD AVENUE  60657   \n",
      "44   45              John S. Arena        4754 NORTH MILWAUKEE AVENUE  60630   \n",
      "45   46            James Cappleman         4544 NORTH BROADWAY AVENUE  60640   \n",
      "46   47                Ameya Pawar          4243 NORTH LINCOLN AVENUE  60618   \n",
      "47   48             Harry Osterman         5533 NORTH BROADWAY AVENUE  60640   \n",
      "48   49                  Joe Moore        7356 NORTH GREENVIEW AVENUE  60626   \n",
      "49   50       Debra L. Silverstein    2949 WEST DEVON AVENUE, SUITE A  60659   \n",
      "\n",
      "    pop_2000  pop_2010 change  \\\n",
      "0      52951     56149     6%   \n",
      "1      54361     55805     3%   \n",
      "2      40385     53039    31%   \n",
      "3      51953     54589     5%   \n",
      "4      55302     51455    -7%   \n",
      "5      54989     52341    -5%   \n",
      "6      54593     51581    -6%   \n",
      "7      54039     51687    -4%   \n",
      "8      52008     51519    -1%   \n",
      "9      56613     51535    -9%   \n",
      "10     64228     51497   -20%   \n",
      "11     68922     52235   -24%   \n",
      "12     64382     53722   -17%   \n",
      "13     80143     54031   -33%   \n",
      "14     56057     51501    -8%   \n",
      "15     50205     51954     3%   \n",
      "16     49264     51846     5%   \n",
      "17     55043     52992    -4%   \n",
      "18     54546     51525    -6%   \n",
      "19     51854     52372     1%   \n",
      "20     51751     51632     0%   \n",
      "21     59734     53515   -10%   \n",
      "22     63691     53728   -16%   \n",
      "23     50879     54909     8%   \n",
      "24     55954     54539    -3%   \n",
      "25     56841     53516    -6%   \n",
      "26     61287     52939   -14%   \n",
      "27     49423     55199    12%   \n",
      "28     61949     55267   -11%   \n",
      "29     72698     55560   -24%   \n",
      "30     65045     53724   -17%   \n",
      "31     57204     55184    -4%   \n",
      "32     63695     55598   -13%   \n",
      "33     49922     51599     3%   \n",
      "34     57588     55281    -4%   \n",
      "35     63376     54766   -14%   \n",
      "36     56120     51538    -8%   \n",
      "37     66011     56001   -15%   \n",
      "38     64291     55882   -13%   \n",
      "39     58652     55319    -6%   \n",
      "40     56127     55991     0%   \n",
      "41     68102     55870   -18%   \n",
      "42     57668     56170    -3%   \n",
      "43     58758     56058    -5%   \n",
      "44     60653     55967    -8%   \n",
      "45     56587     53784    -5%   \n",
      "46     52108     55074     6%   \n",
      "47     56246     55014    -2%   \n",
      "48     59435     54633    -8%   \n",
      "49     62383     55809   -11%   \n",
      "\n",
      "                                            address_y  zip_y  \n",
      "0                         2765 WEST SAINT MARY STREET  60647  \n",
      "1                            WM WASTE MANAGEMENT 1500  60622  \n",
      "2                                 17 EAST 38TH STREET  60653  \n",
      "3             31ST ST HARBOR BUILDING LAKEFRONT TRAIL  60653  \n",
      "4             JACKSON PARK LAGOON SOUTH CORNELL DRIVE  60637  \n",
      "5                                150 WEST 74TH STREET  60636  \n",
      "6                           8549 SOUTH OGLESBY AVENUE  60617  \n",
      "7                          1346-1352 EAST 75TH STREET  60649  \n",
      "8                  11039-11059 SOUTH WENTWORTH AVENUE  60628  \n",
      "9                                10534 SOUTH AVENUE F  46394  \n",
      "10                            943-947 WEST 14TH PLACE  60607  \n",
      "11                         CP 46 STEVENSON EXPRESSWAY  60632  \n",
      "12                    SOUTH RAMP SOUTH LARAMIE AVENUE  60638  \n",
      "13                              4540 WEST 51ST STREET  60632  \n",
      "14    CHICAGO FIRE DEPARTMENT ENGINE COMPANY 123 2215  60632  \n",
      "15                             6036 SOUTH WOOD STREET  60636  \n",
      "16                       7216 SOUTH WINCHESTER AVENUE  60636  \n",
      "17                          3286 WEST COLUMBUS AVENUE  60652  \n",
      "18                        9999 SOUTH FRANCISCO AVENUE  60805  \n",
      "19                     DAN RYAN EXPRESSWAY PARK MANOR  60621  \n",
      "20                     8852-8854 SOUTH EMERALD AVENUE  60620  \n",
      "21                              4233 WEST 36TH STREET  60632  \n",
      "22  CHICAGO MIDWAY INTERNATIONAL AIRPORT WEST 62ND...  60629  \n",
      "23                       1635 SOUTH CHRISTIANA AVENUE  60623  \n",
      "24                      1632-1746 SOUTH MILLER STREET  60608  \n",
      "25             LITTLE CUBS FIELD COMFORT STATION 1400  60622  \n",
      "26                      2151-2153 WEST CHICAGO AVENUE  60651  \n",
      "27                        RML SPECIALTY HOSPITAL 3435  60624  \n",
      "28                        1241 NORTH RIDGELAND AVENUE  60302  \n",
      "29                          5118 WEST FLETCHER STREET  60641  \n",
      "30                          2854 NORTH KEATING AVENUE  60641  \n",
      "31                        2901 NORTH WASHTENAW AVENUE  60618  \n",
      "32                    4041-4043 NORTH RICHMOND STREET  60625  \n",
      "33                    11544-11546 SOUTH PEORIA STREET  60827  \n",
      "34                           3634 WEST BELMONT AVENUE  60618  \n",
      "35                       2918 NORTH RUTHERFORD AVENUE  60634  \n",
      "36                         4738-4748 WEST RICE STREET  60651  \n",
      "37                    7307-7331 WEST IRVING PARK ROAD  60706  \n",
      "38                  QUEEN OF ALL SAINTS BASILICA 6280  60646  \n",
      "39                         5536 NORTH ARTESIAN AVENUE  60645  \n",
      "40                          1652 SOUTH CLIFTON AVENUE  60068  \n",
      "41                          410-420 WEST GRAND AVENUE  60654  \n",
      "42                              LINCOLN PARK ZOO 2001  60614  \n",
      "43                         507-513 WEST ALDINE AVENUE  60657  \n",
      "44       CONGREGATIONAL CHURCH OF JEFFERSON PARK 5320  60630  \n",
      "45                 UPTOWN BROADWAY BUILDING 4743-4763  60640  \n",
      "46                           2153 WEST BERTEAU AVENUE  60618  \n",
      "47                         1025 WEST HOLLYWOOD AVENUE  60660  \n",
      "48                             1426 WEST ESTES AVENUE  60645  \n",
      "49                       2638 WEST NORTH SHORE AVENUE  60645  \n"
     ]
    }
   ],
   "source": [
    "# Объединить таблицы wards и census по столбцу 'ward'\n",
    "wards_census = wards.merge(census, on='ward')\n",
    "\n",
    "# Вывести форму таблицы wards_census\n",
    "print('Форма таблицы wards_census:', wards_census.shape)\n",
    "\n",
    "print(wards_census)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b36e7422cf0ac05",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Инструкции 2/3\n",
    "\n",
    "Объедините таблицы `wards_altered` и `census` в столбце `ward` и обратите внимание на разницу в возвращаемых строках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c0a9f34b85e8a63a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:20.163801Z",
     "start_time": "2024-01-06T05:11:19.996039Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ward\n",
      "0    61\n",
      "1     2\n",
      "2     3\n",
      "3     4\n",
      "4     5\n",
      "Форма таблицы wards_altered_census: (49, 9)\n"
     ]
    }
   ],
   "source": [
    "# Предполагая, что 'wards' и 'census' - это ваши DataFrames\n",
    "\n",
    "# Создать копию DataFrame 'wards' для внесения изменений\n",
    "wards_altered = wards.copy()\n",
    "\n",
    "# Преобразовать столбец 'ward' в целочисленный тип в 'wards_altered'\n",
    "wards_altered['ward'] = wards_altered['ward'].astype(int)\n",
    "\n",
    "# Добавить 60 к первому элементу в столбце 'ward' в 'wards_altered'\n",
    "wards_altered.loc[0, 'ward'] += 60\n",
    "\n",
    "# Вывести несколько первых строк таблицы wards_altered, чтобы увидеть изменение\n",
    "print(wards_altered[['ward']].head())\n",
    "\n",
    "# Проверить, можно ли преобразовать столбец 'ward' в 'census' в целочисленный тип\n",
    "if census['ward'].astype(str).str.isdigit().all():\n",
    "    # Преобразовать столбец 'ward' в 'census' в целочисленный тип\n",
    "    census['ward'] = census['ward'].astype(int)\n",
    "\n",
    "    # Объединить таблицы 'wards_altered' и 'census' по столбцу 'ward'\n",
    "    wards_altered_census = wards_altered.merge(census, on='ward')\n",
    "    print('Форма таблицы wards_altered_census:', wards_altered_census.shape)\n",
    "else:\n",
    "    print(\"Невозможно преобразовать столбец 'ward' в DataFrame 'census' в целочисленный тип для объединения.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a792dec7f5088a8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Инструкции 3/3\n",
    "\n",
    "Объедините таблицы `«ward»` и `«census_altered»` в столбце `«ward»` и обратите внимание на разницу в возвращаемых строках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e0158d6454c2bd0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:20.185366Z",
     "start_time": "2024-01-06T05:11:20.009338Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ward\n",
      "0  None\n",
      "1     2\n",
      "2     3\n",
      "3     4\n",
      "4     5\n",
      "Форма таблицы wards_census_altered: (49, 4)\n"
     ]
    }
   ],
   "source": [
    "# Предполагая, что 'wards' и 'census' - это ваши DataFrames\n",
    "\n",
    "# Создать копию первого столбца DataFrame 'census' и присвоить ему имя 'census_altered'\n",
    "census_altered = census.iloc[:, [0]].copy()\n",
    "\n",
    "# Установить тип столбца 'ward' как строковый для возможности использования значений 'None'\n",
    "census_altered['ward'] = census_altered['ward'].astype(str)\n",
    "\n",
    "# Установить первый элемент в столбце 'ward' в 'None'\n",
    "census_altered.loc[0, 'ward'] = 'None'\n",
    "\n",
    "# Преобразовать столбец 'ward' в 'wards' в строковый тип\n",
    "wards['ward'] = wards['ward'].astype(str)\n",
    "\n",
    "# Объединить таблицы 'wards' и 'census_altered' по столбцу 'ward'\n",
    "wards_census_altered = wards.merge(census_altered, on='ward')\n",
    "\n",
    "# Вывести несколько первых строк таблицы census_altered, чтобы увидеть изменение\n",
    "print(census_altered[['ward']].head())\n",
    "\n",
    "# Вывести форму таблицы wards_census_altered\n",
    "print('Форма таблицы wards_census_altered:', wards_census_altered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eb479140dd542",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Слияние один-ко-многим\n",
    "У бизнеса может быть один или несколько владельцев. В этом упражнении вы продолжите приобретать опыт слияний «один ко многим», объединяя таблицу владельцев бизнеса, называемую `«biz_owners»`, с таблицей `«licenses»`. Вспомните урок: при отношении «один ко многим» строка в левой таблице может повторяться, если она связана с несколькими строками в правой таблице. В этом уроке вы изучите это подробнее, выяснив, какое звание владельца бизнеса является наиболее распространенным. (т. е. секретарь, генеральный директор или вице-президент)\n",
    "\n",
    "DataFrame `licenses` и `biz_owners` загружаются автоматически."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ffffea636e9b695",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:24.917040Z",
     "start_time": "2024-01-06T05:11:20.019250Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл успешно открыт!\n",
      "  account ward  aid                   business               address    zip\n",
      "0  307071    3  743       REGGIE'S BAR & GRILL       2105 S STATE ST  60616\n",
      "1      10   10  829                 HONEYBEERS   13200 S HOUSTON AVE  60633\n",
      "2   10002   14  775                CELINA DELI     5089 S ARCHER AVE  60632\n",
      "3   10005   12  NaN  KRAFT FOODS NORTH AMERICA        2005 W 43RD ST  60609\n",
      "4   10044   44  638  NEYBOUR'S TAVERN & GRILLE  3651 N SOUTHPORT AVE  60613\n"
     ]
    }
   ],
   "source": [
    "# Получить текущую директорию\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Перейти в папку datasets\n",
    "datasets_directory = os.path.join(current_directory, 'datasets')\n",
    "\n",
    "# Проверить, существует ли файл в папке datasets\n",
    "file_path = os.path.join(datasets_directory, 'licenses.p')\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # Файл существует, поэтому откройте его\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    # Работайте с объектом 'data' по необходимости\n",
    "    print(\"Файл успешно открыт!\")\n",
    "else:\n",
    "    print(\"Файл не найден.\")\n",
    "licenses = data\n",
    "print(licenses.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "12c4b449a2321279",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:28.595203Z",
     "start_time": "2024-01-06T05:11:24.924124Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл успешно открыт!\n",
      "  account first_name  last_name      title\n",
      "0      10      PEARL    SHERMAN  PRESIDENT\n",
      "1      10      PEARL    SHERMAN  SECRETARY\n",
      "2   10002     WALTER     MROZEK    PARTNER\n",
      "3   10002     CELINA     BYRDAK    PARTNER\n",
      "4   10005      IRENE  ROSENFELD  PRESIDENT\n"
     ]
    }
   ],
   "source": [
    "# Получить текущую директорию\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Перейти в папку datasets\n",
    "datasets_directory = os.path.join(current_directory, 'datasets')\n",
    "\n",
    "# Проверить, существует ли файл в папке datasets\n",
    "file_path = os.path.join(datasets_directory, 'business_owners.p')\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # Файл существует, поэтому откройте его\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    # Работайте с объектом 'data' по необходимости\n",
    "    print(\"Файл успешно открыт!\")\n",
    "else:\n",
    "    print(\"Файл не найден.\")\n",
    "biz_owners = data\n",
    "\n",
    "print(biz_owners.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05c6310d4864028",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Инструкции\n",
    "\n",
    "– Начиная с таблицы `«licenses»` слева, объедините ее с таблицей `«biz_owners»` в столбце `«account»` и сохраните результаты в переменной с именем `«licenses_owners»`.\n",
    "- Сгруппируйте `licenses_owners` по `title` и подсчитайте количество аккаунтов для каждого титула. Сохраните результат как counted_df.\n",
    "- Отсортируйте `counted_df` по количеству ***аккаунтов*** в ***по убыванию*** и сохраните это значение как переменную с именем `sorted_df`.\n",
    "- Используйте метод `.head()` для печати первых нескольких строк `sorted_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e73d411abbc9735",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:28.680286Z",
     "start_time": "2024-01-06T05:11:28.610605Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 account\n",
      "title                   \n",
      "PRESIDENT           6259\n",
      "SECRETARY           5205\n",
      "SOLE PROPRIETOR     1658\n",
      "OTHER               1200\n",
      "VICE PRESIDENT       970\n"
     ]
    }
   ],
   "source": [
    "# Объединить таблицы licenses и biz_owners по столбцу 'account'\n",
    "licenses_owners = licenses.merge(biz_owners, on='account')\n",
    "\n",
    "# Сгруппировать результаты по столбцу 'title' и подсчитать количество учетных записей\n",
    "counted_df = licenses_owners.groupby('title').agg({'account':'count'})\n",
    "\n",
    "# Отсортировать counted_df в порядке убывания\n",
    "sorted_df = counted_df.sort_values(by='account', ascending=False)\n",
    "\n",
    "# Использовать метод .head() для вывода нескольких первых строк sorted_df\n",
    "print(sorted_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc48e14ae6a900d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Всего пассажиров за месяц\n",
    "Ваша цель — найти общее количество поездок, выполненных пассажирами, проезжающими через станцию Уилсон (`station_name == 'Wilson'`) при поездке в системе общественного транспорта Чикаго в будние дни (`day_type == 'Weekday'`) в июле (месяц). == 7). К счастью, Чикаго предоставляет эти подробные данные, но они представлены в трех разных таблицах. Чтобы ответить на вопрос, вам предстоит объединить эти таблицы. Эти данные отличаются от данных, связанных с бизнесом, которые вы видели до сих пор, но предоставляется вся информация, необходимая для ответа на вопрос.\n",
    "\n",
    "Для вас загружены кадры данных `«cal»`, `«ridership» и «stations»`. Взаимосвязь между таблицами можно увидеть на диаграмме ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26f74b410d43802",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![The relationship between the tables](datasets/cta_L_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e64a58e353590530",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:28.800127Z",
     "start_time": "2024-01-06T05:11:28.643216Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл успешно открыт!\n",
      "   year  month  day        day_type\n",
      "0  2019      1    1  Sunday/Holiday\n",
      "1  2019      1    2         Weekday\n",
      "2  2019      1    3         Weekday\n",
      "3  2019      1    4         Weekday\n",
      "4  2019      1    5        Saturday\n"
     ]
    }
   ],
   "source": [
    "# Получить текущую директорию\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Перейти в папку datasets\n",
    "datasets_directory = os.path.join(current_directory, 'datasets')\n",
    "\n",
    "# Проверить, существует ли файл в папке datasets\n",
    "file_path = os.path.join(datasets_directory, 'cta_calendar.p')\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # Файл существует, поэтому откройте его\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    # Работайте с объектом 'data' по необходимости\n",
    "    print(\"Файл успешно открыт!\")\n",
    "else:\n",
    "    print(\"Файл не найден.\")\n",
    "cal = data\n",
    "\n",
    "print(cal.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40df06f7f411f847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:29.194331Z",
     "start_time": "2024-01-06T05:11:28.798900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл успешно открыт!\n",
      "  station_id  year  month  day  rides\n",
      "0      40010  2019      1    1    576\n",
      "1      40010  2019      1    2   1457\n",
      "2      40010  2019      1    3   1543\n",
      "3      40010  2019      1    4   1621\n",
      "4      40010  2019      1    5    719\n"
     ]
    }
   ],
   "source": [
    "# Получить текущую директорию\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Перейти в папку datasets\n",
    "datasets_directory = os.path.join(current_directory, 'datasets')\n",
    "\n",
    "# Проверить, существует ли файл в папке datasets\n",
    "file_path = os.path.join(datasets_directory, 'cta_ridership.p')\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # Файл существует, поэтому откройте его\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    # Работайте с объектом 'data' по необходимости\n",
    "    print(\"Файл успешно открыт!\")\n",
    "else:\n",
    "    print(\"Файл не найден.\")\n",
    "ridership = data\n",
    "\n",
    "print(ridership.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f9435b27ca2a7346",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:29.358140Z",
     "start_time": "2024-01-06T05:11:29.196342Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found.\n",
      "  station_id  year  month  day  rides\n",
      "0      40010  2019      1    1    576\n",
      "1      40010  2019      1    2   1457\n",
      "2      40010  2019      1    3   1543\n",
      "3      40010  2019      1    4   1621\n",
      "4      40010  2019      1    5    719\n"
     ]
    }
   ],
   "source": [
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Navigate to the datasets folder\n",
    "datasets_directory = os.path.join(current_directory, '..', 'datasets')\n",
    "\n",
    "# Check if the file exists in the datasets folder\n",
    "file_path = os.path.join(datasets_directory, 'stations.p')\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # File exists, so open it\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    # Work with the 'data' object as needed\n",
    "    print(\"File opened successfully!\")\n",
    "else:\n",
    "    print(\"File not found.\")\n",
    "stations = data\n",
    "\n",
    "print(stations.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c985aff2e8cc3f6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Инструкции 1/3\n",
    "\n",
    "Объедините таблицы `«ridership»` и `«cal»`, начиная с таблицы `«ridership»` слева, и сохраните результат в переменной `«ridership_cal»`. Если ваш код выполняется слишком долго, ваши условия слияния могут быть неправильными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d1875ab33763d9bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:29.368178Z",
     "start_time": "2024-01-06T05:11:29.360239Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Объединить таблицы ridership и cal\n",
    "ridership_cal = ridership.merge(cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52fbcf9e6bd0215",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Инструкции 2/3\n",
    "\n",
    "Расширьте предыдущее объединение до трех таблиц, объединив также таблицу `stations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cd2600801ec59957",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:29.422114Z",
     "start_time": "2024-01-06T05:11:29.372030Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        station_id  year_x  month_x  day_x  rides_x        day_type  year_y  \\\n",
      "0            40010    2019        1      1      576  Sunday/Holiday    2019   \n",
      "1            40010    2019        1      1      576  Sunday/Holiday    2019   \n",
      "2            40010    2019        1      1      576  Sunday/Holiday    2019   \n",
      "3            40010    2019        1      1      576  Sunday/Holiday    2019   \n",
      "4            40010    2019        1      1      576  Sunday/Holiday    2019   \n",
      "...            ...     ...      ...    ...      ...             ...     ...   \n",
      "1199020      41660    2019       12     31    13430         Weekday    2019   \n",
      "1199021      41660    2019       12     31    13430         Weekday    2019   \n",
      "1199022      41660    2019       12     31    13430         Weekday    2019   \n",
      "1199023      41660    2019       12     31    13430         Weekday    2019   \n",
      "1199024      41660    2019       12     31    13430         Weekday    2019   \n",
      "\n",
      "         month_y  day_y  rides_y  \n",
      "0              1      1      576  \n",
      "1              1      2     1457  \n",
      "2              1      3     1543  \n",
      "3              1      4     1621  \n",
      "4              1      5      719  \n",
      "...          ...    ...      ...  \n",
      "1199020       12     27    13898  \n",
      "1199021       12     28     9485  \n",
      "1199022       12     29     7581  \n",
      "1199023       12     30    15332  \n",
      "1199024       12     31    13430  \n",
      "\n",
      "[1199025 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge the ridership, cal, and stations tables\n",
    "ridership_cal_stations = ridership.merge(cal, on=['year','month','day']) \\\n",
    "    .merge(stations, on=['station_id'])\n",
    "\n",
    "print(ridership_cal_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27e08a2a9ddcfa6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Инструкции 3/3\n",
    "\n",
    "Создайте переменную с именем `filter_criteria`, чтобы выбрать соответствующие строки из объединенной таблицы и суммировать столбец `rides`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "63f83547bfe7e94e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:29.425066Z",
     "start_time": "2024-01-06T05:11:29.391109Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'month'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'month'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[65], line 6\u001B[0m\n\u001B[1;32m      2\u001B[0m ridership_cal_stations \u001B[38;5;241m=\u001B[39m ridership\u001B[38;5;241m.\u001B[39mmerge(cal, on\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124myear\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmonth\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mday\u001B[39m\u001B[38;5;124m'\u001B[39m]) \\\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;241m.\u001B[39mmerge(stations, on\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstation_id\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Создать фильтр для фильтрации ridership_cal_stations\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m filter_criteria \u001B[38;5;241m=\u001B[39m ((\u001B[43mridership_cal_stations\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmonth\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m7\u001B[39m)\n\u001B[1;32m      7\u001B[0m                    \u001B[38;5;241m&\u001B[39m (ridership_cal_stations[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mday_type\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWeekday\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      8\u001B[0m                    \u001B[38;5;241m&\u001B[39m (ridership_cal_stations[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstation_name\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWilson\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Использовать .loc и фильтр для выбора поездок\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(ridership_cal_stations\u001B[38;5;241m.\u001B[39mloc[filter_criteria, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrides\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39msum())\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3807\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3809\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3804\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'month'"
     ]
    }
   ],
   "source": [
    "# Объединить таблицы ridership, cal и stations\n",
    "ridership_cal_stations = ridership.merge(cal, on=['year', 'month', 'day']) \\\n",
    "    .merge(stations, on='station_id')\n",
    "\n",
    "# Создать фильтр для фильтрации ridership_cal_stations\n",
    "filter_criteria = ((ridership_cal_stations['month'] == 7)\n",
    "                   & (ridership_cal_stations['day_type'] == 'Weekday')\n",
    "                   & (ridership_cal_stations['station_name'] == 'Wilson'))\n",
    "\n",
    "# Использовать .loc и фильтр для выбора поездок\n",
    "print(ridership_cal_stations.loc[filter_criteria, 'rides'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ce80bb6b6d263",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Объединение трех таблиц\n",
    "Чтобы закрепить концепцию слияния трех DataFrame, выполните еще одно упражнение. Разумное расширение нашего обзора бизнес-данных Чикаго могло бы включать рассмотрение демографической информации о районах, где расположены предприятия. Вам предоставлена таблица медианного дохода по почтовому индексу. Вы объедините таблицы лицензий и подопечных с новой таблицей дохода по почтовому индексу под названием `zip_demo`.\n",
    "\n",
    "Фреймы данных `licenses`, `ward` и `zip_demo` уже загружены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "59cac944c47f42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:29.626687Z",
     "start_time": "2024-01-06T05:11:29.407628Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл успешно открыт!\n",
      "     zip  income\n",
      "0  60630   70122\n",
      "1  60640   50488\n",
      "2  60622   87143\n",
      "3  60614  100116\n",
      "4  60608   41226\n"
     ]
    }
   ],
   "source": [
    "# Получить текущий каталог\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Перейти в каталог с данными\n",
    "datasets_directory = os.path.join(current_directory, 'datasets')\n",
    "\n",
    "# Проверить, существует ли файл в каталоге с данными\n",
    "file_path = os.path.join(datasets_directory, 'zip_demo.p')\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # Файл существует, поэтому открываем его\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    # Работаем с объектом 'data' по необходимости\n",
    "    print(\"Файл успешно открыт!\")\n",
    "else:\n",
    "    print(\"Файл не найден.\")\n",
    "zip_demo = data\n",
    "\n",
    "print(zip_demo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d2d86db21c76c1fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:29.686934Z",
     "start_time": "2024-01-06T05:11:29.630872Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             income\n",
      "alderman                           \n",
      "Ameya Pawar                 66246.0\n",
      "Anthony A. Beale            38206.0\n",
      "Anthony V. Napolitano       82226.0\n",
      "Ariel E. Reyboras           41307.0\n",
      "Brendan Reilly             110215.0\n",
      "Brian Hopkins               87143.0\n",
      "Carlos Ramirez-Rosa         66246.0\n",
      "Carrie M. Austin            38206.0\n",
      "Chris Taliaferro            55566.0\n",
      "Daniel \"Danny\" Solis        41226.0\n",
      "David H. Moore              33304.0\n",
      "Deborah Mell                66246.0\n",
      "Debra L. Silverstein        50554.0\n",
      "Derrick G. Curtis           65770.0\n",
      "Edward M. Burke             42335.0\n",
      "Emma M. Mitts               36283.0\n",
      "George Cardenas             33959.0\n",
      "Gilbert Villegas            41307.0\n",
      "Gregory I. Mitchell         24941.0\n",
      "Harry Osterman              45442.0\n",
      "Howard B. Brookins, Jr.     33304.0\n",
      "James Cappleman             79565.0\n",
      "Jason C. Ervin              41226.0\n",
      "Joe Moore                   39163.0\n",
      "John S. Arena               70122.0\n",
      "Leslie A. Hairston          28024.0\n",
      "Margaret Laurino            70122.0\n",
      "Marty Quinn                 67045.0\n",
      "Matthew J. O'Shea           59488.0\n",
      "Michael R. Zalewski         42335.0\n",
      "Michael Scott, Jr.          31445.0\n",
      "Michelle A. Harris          32558.0\n",
      "Michelle Smith             100116.0\n",
      "Milagros \"Milly\" Santiago   41307.0\n",
      "Nicholas Sposato            62223.0\n",
      "Pat Dowell                  46340.0\n",
      "Patrick Daley Thompson      41226.0\n",
      "Patrick J. O'Connor         50554.0\n",
      "Proco \"Joe\" Moreno          87143.0\n",
      "Raymond A. Lopez            33959.0\n",
      "Ricardo Munoz               31445.0\n",
      "Roberto Maldonado           68223.0\n",
      "Roderick T. Sawyer          32558.0\n",
      "Scott Waguespack            68223.0\n",
      "Susan Sadlowski Garza       38417.0\n",
      "Tom Tunney                  88708.0\n",
      "Toni L. Foulkes             27573.0\n",
      "Walter Burnett, Jr.         87143.0\n",
      "William D. Burns           107811.0\n",
      "Willie B. Cochran           28024.0\n"
     ]
    }
   ],
   "source": [
    "# Объединить лицензии и zip_demo по zip; и объединить районы по ward\n",
    "licenses_zip_ward = licenses.merge(zip_demo, on=['zip']) \\\n",
    "    .merge(wards, on=['ward'])\n",
    "\n",
    "# Вывести результаты по альдерменам и показать медианный доход\n",
    "print(licenses_zip_ward.groupby('alderman').agg({'income': 'median'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eccafdc96d963c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Слияние «один ко многим» с несколькими таблицами\n",
    "\n",
    "Предположим, что в этом упражнении вы хотите начать бизнес в Чикаго. Ваша идеальная идея — основать компанию, которая будет использовать коз для стрижки газонов для других предприятий. Однако вам нужно выбрать место в городе, чтобы разместить свою козью ферму. Вам нужно место с большим пространством и относительно небольшим количеством предприятий и людей вокруг, чтобы избежать жалоб на запах. Вам нужно будет объединить три таблицы, чтобы выбрать свое местоположение. Таблица `Land_use` содержит информацию о проценте свободной земли по городским округам. В таблице переписи населения указано население по округам, а в таблице лицензий перечислены предприятия по округам.\n",
    "\n",
    "Таблицы `«land_use»`, `«census»` и `«licenses»` уже загружены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2f4d62ad0aaa674",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:11:29.773561Z",
     "start_time": "2024-01-06T05:11:29.659619Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл успешно открыт!\n",
      "  ward  residential  commercial  industrial  vacant  other\n",
      "0    1           41           9           2       2     46\n",
      "1    2           31          11           6       2     50\n",
      "2    3           20           5           3      13     59\n",
      "3    4           22          13           0       7     58\n",
      "4    5           25           3           1       3     68\n"
     ]
    }
   ],
   "source": [
    "# Получить текущий каталог\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Перейти в каталог с данными\n",
    "datasets_directory = os.path.join(current_directory, 'datasets')\n",
    "\n",
    "# Проверить, существует ли файл в каталоге с данными\n",
    "file_path = os.path.join(datasets_directory, 'land_use.p')\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # Файл существует, поэтому открываем его\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    # Работаем с объектом 'data' по необходимости\n",
    "    print(\"Файл успешно открыт!\")\n",
    "else:\n",
    "    print(\"Файл не найден.\")\n",
    "land_use = data\n",
    "\n",
    "print(land_use.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6601b1d146385173",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Инструкции 1/3\n",
    "\n",
    "Объедините данные `«land_use»` и `«census»` в столбце `«ward»`. Объедините результат с «лицензиями» в столбце `«ward»`, используя суффикс `«_cen»` для левой таблицы и `«_lic»` для правой таблицы. Сохраните это в переменной `«land_cen_lic».`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a290a04fdfbb6b7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:21:58.698283Z",
     "start_time": "2024-01-06T05:21:58.668430Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the 'ward' column in the land_use DataFrame to the same data type as other DataFrames\n",
    "land_use['ward'] = land_use['ward'].astype(int)\n",
    "\n",
    "# Merge land_use and census on the ward column\n",
    "merged_data = pd.merge(land_use, census, on='ward')\n",
    "\n",
    "# Convert the 'ward' column in the licenses DataFrame to the same data type\n",
    "licenses['ward'] = licenses['ward'].astype(int)\n",
    "\n",
    "# Merge merged_data and licenses on the ward column, providing suffixes for clarity\n",
    "land_cen_lic = pd.merge(merged_data, licenses, on='ward', suffixes=('_cen', '_lic'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924ee0c50a72b257",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Инструкции 2/3\n",
    "\n",
    "Сгруппируйте `land_cen_lic` по `ward`, `pop_2010` (население в 2010 году) и `vacant`, затем подсчитайте количество `accounts`. Сохраните результаты в `pop_vac_lic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fc5b4418d0185aa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:24:09.716394Z",
     "start_time": "2024-01-06T05:24:09.684796Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Group by ward, pop_2010, and vacant, then count the # of accounts\n",
    "pop_vac_lic = land_cen_lic.groupby(['ward','pop_2010', 'vacant'],\n",
    "                                   as_index=False).agg({'account':'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2abf8053a1a0d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Инструкции 3/3\n",
    "\n",
    "Отсортируйте `pop_vac_lic` по `vacant`, `account` и `pop_2010` в порядке убывания, возрастания и возрастания соответственно. Сохраните его как `sorted_pop_vac_lic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1f3ae74b6446a7c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T05:24:12.007434Z",
     "start_time": "2024-01-06T05:24:11.972511Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ward  pop_2010  vacant  account\n",
      "6      7     51581      19       80\n",
      "19    20     52372      15      123\n",
      "9     10     51535      14      130\n",
      "23    24     54909      13       98\n",
      "15    16     51954      13      156\n"
     ]
    }
   ],
   "source": [
    "# Sort pop_vac_lic and print the results\n",
    "sorted_pop_vac_lic = pop_vac_lic.sort_values(by=['vacant', 'account', 'pop_2010'],\n",
    "                                             ascending=[False, True, True])\n",
    "\n",
    "# Print the top few rows of sorted_pop_vac_lic\n",
    "print(sorted_pop_vac_lic.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
