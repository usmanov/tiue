{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d50724026055da",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ca47967f470c437",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Манипулирование данными с помощью Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b781dad3",
   "metadata": {},
   "source": [
    "## Агрегация фреймов данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30207ba",
   "metadata": {},
   "source": [
    "### Среднее и медиана\n",
    "\n",
    "Статистика обзора - это именно то, что звучит - она подводит итог многим числам в одной статистике. Например, среднее, медиана, минимум, максимум и стандартное отклонение - это статистика обзора. Рассчет статистики обзора позволяет лучше понять ваши данные, даже если их много.\n",
    "\n",
    "`sales` доступен, и pandas загружен как pd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e2d11e1d98220",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Инструкции\n",
    "\n",
    "- Изучите свой новый DataFrame, сначала распечатав первые несколько строк DataFrame sales.\n",
    "- Выведите информацию о столбцах в `sales`.\n",
    "- Выведите среднее значение столбца `weekly_sales`.\n",
    "- Выведите медиану столбца `weekly_sales`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-23T10:42:31.009642Z",
     "start_time": "2024-03-23T10:42:30.985146Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import mean\n",
    "\n",
    "sales = pd.read_csv('datasets/sales_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6484b4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T09:35:13.988847Z",
     "start_time": "2024-03-23T09:35:13.959449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0  store type  department        date  weekly_sales  is_holiday  \\\n0           0      1    A           1  2010-02-05      24924.50       False   \n1           1      1    A           1  2010-03-05      21827.90       False   \n2           2      1    A           1  2010-04-02      57258.43       False   \n3           3      1    A           1  2010-05-07      17413.94       False   \n4           4      1    A           1  2010-06-04      17558.09       False   \n\n   temperature_c  fuel_price_usd_per_l  unemployment  \n0       5.727778              0.679451         8.106  \n1       8.055556              0.693452         8.106  \n2      16.816667              0.718284         7.808  \n3      22.527778              0.748928         7.808  \n4      27.050000              0.714586         7.808  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>store</th>\n      <th>type</th>\n      <th>department</th>\n      <th>date</th>\n      <th>weekly_sales</th>\n      <th>is_holiday</th>\n      <th>temperature_c</th>\n      <th>fuel_price_usd_per_l</th>\n      <th>unemployment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>A</td>\n      <td>1</td>\n      <td>2010-02-05</td>\n      <td>24924.50</td>\n      <td>False</td>\n      <td>5.727778</td>\n      <td>0.679451</td>\n      <td>8.106</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>A</td>\n      <td>1</td>\n      <td>2010-03-05</td>\n      <td>21827.90</td>\n      <td>False</td>\n      <td>8.055556</td>\n      <td>0.693452</td>\n      <td>8.106</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>A</td>\n      <td>1</td>\n      <td>2010-04-02</td>\n      <td>57258.43</td>\n      <td>False</td>\n      <td>16.816667</td>\n      <td>0.718284</td>\n      <td>7.808</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1</td>\n      <td>A</td>\n      <td>1</td>\n      <td>2010-05-07</td>\n      <td>17413.94</td>\n      <td>False</td>\n      <td>22.527778</td>\n      <td>0.748928</td>\n      <td>7.808</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n      <td>A</td>\n      <td>1</td>\n      <td>2010-06-04</td>\n      <td>17558.09</td>\n      <td>False</td>\n      <td>27.050000</td>\n      <td>0.714586</td>\n      <td>7.808</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<bound method DataFrame.info of        Unnamed: 0  store type  department        date  weekly_sales  \\\n0               0      1    A           1  2010-02-05      24924.50   \n1               1      1    A           1  2010-03-05      21827.90   \n2               2      1    A           1  2010-04-02      57258.43   \n3               3      1    A           1  2010-05-07      17413.94   \n4               4      1    A           1  2010-06-04      17558.09   \n...           ...    ...  ...         ...         ...           ...   \n10769       10769     39    A          99  2011-12-09        895.00   \n10770       10770     39    A          99  2012-02-03        350.00   \n10771       10771     39    A          99  2012-06-08        450.00   \n10772       10772     39    A          99  2012-07-13          0.06   \n10773       10773     39    A          99  2012-10-05        915.00   \n\n       is_holiday  temperature_c  fuel_price_usd_per_l  unemployment  \n0           False       5.727778              0.679451         8.106  \n1           False       8.055556              0.693452         8.106  \n2           False      16.816667              0.718284         7.808  \n3           False      22.527778              0.748928         7.808  \n4           False      27.050000              0.714586         7.808  \n...           ...            ...                   ...           ...  \n10769       False       9.644444              0.834256         7.716  \n10770       False      15.938889              0.887619         7.244  \n10771       False      27.288889              0.911922         6.989  \n10772       False      25.644444              0.860145         6.623  \n10773       False      22.250000              0.955511         6.228  \n\n[10774 rows x 10 columns]>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "23843.95014850566"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "12049.064999999999"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Распечатать первые строки DataFrame sales\n",
    "display(sales.head())\n",
    "\n",
    "# Вывести информацию о DataFrame sales\n",
    "display(sales.info)\n",
    "\n",
    "# Вывести среднее значение weekly_sales\n",
    "display(sales['weekly_sales'].mean())\n",
    "\n",
    "# Вывести медиану weekly_sales\n",
    "display(sales['weekly_sales'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab52eb7c",
   "metadata": {},
   "source": [
    "### Суммирование дат\n",
    "\n",
    "Сводная статистика также может быть рассчитана для столбцов с датами, значения которых имеют тип данных `datetime64`. Некоторые сводные статистики, например, среднее значение, не имеют особого смысла для дат, но другие очень полезны, например, минимум и максимум, которые позволяют увидеть диапазон времени, охватываемый вашими данными.\n",
    "\n",
    "`sales` доступен, и pandas загружен как pd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bf81c3a9e9df45",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Инструкции\n",
    "\n",
    "- Выведите максимум столбца даты (date).\n",
    "- Выведите минимум столбца даты (date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "975fde74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T07:00:55.033991Z",
     "start_time": "2024-03-18T07:00:55.022242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'2012-10-26'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'2010-02-05'"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Вывести максимум столбца даты\n",
    "display(sales['date'].max())\n",
    "# Вывести минимум столбца даты\n",
    "display(sales['date'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e214d1",
   "metadata": {},
   "source": [
    "### Эффективные сводки\n",
    "\n",
    "Хотя у `pandas` и `NumPy` есть множество функций, иногда вам может понадобиться другая функция для сводки ваших данных.\n",
    "\n",
    "Метод `.agg()` позволяет применять ваши собственные пользовательские функции к DataFrame, а также применять функции к более чем одному столбцу DataFrame одновременно, делая ваши агрегации очень эффективными. Например,\n",
    "\n",
    "    df['столбец'].agg(функция)\n",
    "    \n",
    "В пользовательской функции для этого упражнения \"IQR\" означает интерквартильный размах, который представляет собой разницу между 75-м и 25-м процентилем. Это альтернатива стандартному отклонению, полезная, если в ваших данных есть выбросы.\n",
    "\n",
    "`sales` доступен, а pandas загружен как pd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f181fc12c95e11c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Инструкции\n",
    "\n",
    "1. Используйте определенную для вас пользовательскую функцию `iqr` вместе с `.agg()`, чтобы вывести интерквартильный размах (IQR) столбца `temperature_c` из `sales`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08e9ad3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T07:04:19.431106Z",
     "start_time": "2024-03-18T07:04:19.422293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.583333333333336\n"
     ]
    }
   ],
   "source": [
    "# Пользовательская функция IQR\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "    \n",
    "# Вывести IQR столбца temperature_c \n",
    "print(sales['temperature_c'].agg(iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfaa07f",
   "metadata": {},
   "source": [
    "2. Обновите выбор столбцов, используя пользовательскую функцию `iqr` с `.agg()`, чтобы вывести интерквартильный размах (IQR) `temperature_c`, `fuel_price_usd_per_l` и `unemployment`, в таком порядке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdbfe702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T07:06:17.949693Z",
     "start_time": "2024-03-18T07:06:17.936569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature_c           16.583333\n",
      "fuel_price_usd_per_l     0.073176\n",
      "unemployment             0.565000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Пользовательская функция IQR\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Обновить для вывода IQR temperature_c, fuel_price_usd_per_l и unemployment\n",
    "print(sales[['temperature_c','fuel_price_usd_per_l','unemployment']].agg(iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b22e17",
   "metadata": {},
   "source": [
    "3. Обновите функции агрегации, вызываемые `.agg()`: включите `iqr` и `np.median` в таком порядке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ea0a862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T07:09:50.906716Z",
     "start_time": "2024-03-18T07:09:50.886829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        temperature_c  fuel_price_usd_per_l  unemployment\n",
      "iqr         16.583333              0.073176         0.565\n",
      "median      16.966667              0.743381         8.099\n"
     ]
    }
   ],
   "source": [
    "# Импортировать NumPy и создать пользовательскую функцию IQR\n",
    "import numpy as np\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Обновить для вывода IQR и медианы temperature_c, fuel_price_usd_per_l и unemployment\n",
    "print(sales[['temperature_c','fuel_price_usd_per_l','unemployment']].agg([iqr,np.median]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7b8c94",
   "metadata": {},
   "source": [
    "### Статистика по накоплению\n",
    "\n",
    "Кумулятивная статистика также может быть полезной для отслеживания суммарной статистики с течением времени. В этом упражнении вы будете вычислять кумулятивную сумму и кумулятивный максимум еженедельных продаж отдела, что позволит вам определить, какова была общая сумма продаж на текущий момент, а также каковы были максимальные еженедельные продажи на данный момент.\n",
    "\n",
    "Создан DataFrame под названием `sales_1_1`, который содержит данные о продажах для отдела 1 магазина 1. pandas загружен как pd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51c904e",
   "metadata": {},
   "source": [
    "#### Инструкции\n",
    "\n",
    "- Отсортировать строки `sales_1_1` по столбцу `date` в порядке возрастания.\n",
    "- Получить накопительную сумму `weekly_sales` и добавить ее как новый столбец `sales_1_1` под названием `cum_weekly_sales`.\n",
    "- Получить накопительный максимум `weekly_sales` и добавить его как столбец под названием `cum_max_sales`.\n",
    "- Вывести столбцы `date`, `weekly_sales`, `cum_weekly_sales` и `cum_max_sales`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93596e8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T07:33:40.063701Z",
     "start_time": "2024-03-18T07:33:40.042784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date  weekly_sales  cum_weekly_sales  cum_max_sales\n",
      "0      2010-02-05      24924.50      2.492450e+04       24924.50\n",
      "6437   2010-02-05      38597.52      6.352202e+04       38597.52\n",
      "1249   2010-02-05       3840.21      6.736223e+04       38597.52\n",
      "6449   2010-02-05      17590.59      8.495282e+04       38597.52\n",
      "6461   2010-02-05       4929.87      8.988269e+04       38597.52\n",
      "...           ...           ...               ...            ...\n",
      "3592   2012-10-05        440.00      2.568932e+08      293966.05\n",
      "8108   2012-10-05        660.00      2.568938e+08      293966.05\n",
      "10773  2012-10-05        915.00      2.568947e+08      293966.05\n",
      "6257   2012-10-12          3.00      2.568947e+08      293966.05\n",
      "3384   2012-10-26        -21.63      2.568947e+08      293966.05\n",
      "\n",
      "[10774 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Сортировка sales по дате\n",
    "sales_1_1 = sales.sort_values('date', ascending=True)\n",
    "\n",
    "# Получение накопительной суммы weekly_sales, добавление в качестве столбца cum_weekly_sales\n",
    "sales_1_1['cum_weekly_sales'] = sales_1_1['weekly_sales'].cumsum() \n",
    "\n",
    "# Получение накопительного максимума weekly_sales, добавление в качестве столбца cum_max_sales\n",
    "sales_1_1['cum_max_sales'] = sales_1_1['weekly_sales'].cummax()\n",
    "# Просмотр столбцов, которые вы вычислили\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6007f81b",
   "metadata": {},
   "source": [
    "### Удаление дубликатов\n",
    "\n",
    "Удаление дубликатов - это важный навык для получения точных подсчетов, потому что часто необходимо избежать учета одного и того же элемента несколько раз. В этом упражнении вы создадите несколько новых DataFrame, используя уникальные значения из `sales`.\n",
    "\n",
    "Доступен DataFrame `sales`, и pandas импортирован как pd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f48d67c",
   "metadata": {},
   "source": [
    "#### Инструкции\n",
    "\n",
    "- Удалите строки из `sales` с повторяющимися парами `store` и `type`, сохраните как `store_types` и выведите `head`.\n",
    "- Удалите строки из `sales` с повторяющимися парами `store` и `department`, сохраните как `store_depts` и выведите `head`.\n",
    "- Выберите строки, соответствующие неделям праздников, используя столбец `is_holiday`, и удалите повторяющиеся `dates`, сохраните как `holiday_dates`.\n",
    "- Выберите столбец `date` из `holiday_dates` и выведите его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf99a82f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T08:02:34.083813Z",
     "start_time": "2024-03-18T08:02:34.064168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  store type  department        date  weekly_sales  \\\n",
      "0              0      1    A           1  2010-02-05      24924.50   \n",
      "901          901      2    A           1  2010-02-05      35034.06   \n",
      "1798        1798      4    A           1  2010-02-05      38724.42   \n",
      "2699        2699      6    A           1  2010-02-05      25619.00   \n",
      "3593        3593     10    B           1  2010-02-05      40212.84   \n",
      "\n",
      "      is_holiday  temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0          False       5.727778              0.679451         8.106  \n",
      "901        False       4.550000              0.679451         8.324  \n",
      "1798       False       6.533333              0.686319         8.623  \n",
      "2699       False       4.683333              0.679451         7.259  \n",
      "3593       False      12.411111              0.782478         9.765  \n",
      "    Unnamed: 0  store type  department        date  weekly_sales  is_holiday  \\\n",
      "0            0      1    A           1  2010-02-05      24924.50       False   \n",
      "12          12      1    A           2  2010-02-05      50605.27       False   \n",
      "24          24      1    A           3  2010-02-05      13740.12       False   \n",
      "36          36      1    A           4  2010-02-05      39954.04       False   \n",
      "48          48      1    A           5  2010-02-05      32229.38       False   \n",
      "\n",
      "    temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0        5.727778              0.679451         8.106  \n",
      "12       5.727778              0.679451         8.106  \n",
      "24       5.727778              0.679451         8.106  \n",
      "36       5.727778              0.679451         8.106  \n",
      "48       5.727778              0.679451         8.106  \n",
      "            date\n",
      "498   2010-09-10\n",
      "691   2011-11-25\n",
      "2315  2010-02-12\n",
      "6735  2012-09-07\n",
      "6810  2010-12-31\n",
      "6815  2012-02-10\n",
      "6820  2011-09-09\n"
     ]
    }
   ],
   "source": [
    "# Удалить повторяющиеся комбинации магазинов/типов\n",
    "store_types = sales.drop_duplicates(subset=['store', 'type'])\n",
    "\n",
    "print(store_types.head())\n",
    "\n",
    "# Удалить повторяющиеся комбинации магазинов/отделов\n",
    "store_depts = sales.drop_duplicates(subset=['store', 'department'])\n",
    "print(store_depts.head())\n",
    "\n",
    "# Выбрать строки, где is_holiday равно True, и удалить повторяющиеся даты\n",
    "holiday_dates = sales[sales['is_holiday']].drop_duplicates(subset=['date'])\n",
    "\n",
    "# Вывести столбец date из holiday_dates\n",
    "print(holiday_dates[['date']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd9fc4d",
   "metadata": {},
   "source": [
    "### Подсчет категориальных переменных\n",
    "\n",
    "Подсчет - отличный способ получить обзор данных и заметить любопытные особенности, которые вы могли бы упустить иначе. В этом упражнении вы посчитаете количество каждого типа магазина и количество каждого номера отдела, используя DataFrame, созданные в предыдущем упражнении:\n",
    "\n",
    "DataFrame `store_types` и `store_depts`, созданные в последнем упражнении, доступны, и `pandas` импортирован как `pd`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b100afc",
   "metadata": {},
   "source": [
    "#### Инструкции\n",
    "\n",
    "- Посчитайте количество магазинов каждого типа в `store_types`.\n",
    "- Посчитайте долю магазинов каждого типа в `store_types`.\n",
    "- Посчитайте количество различных отделов в `store_depts`, отсортировав подсчеты по убыванию.\n",
    "- Посчитайте долю различных отделов в `store_depts`, отсортировав доли по убыванию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "953e30f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T08:57:55.579345Z",
     "start_time": "2024-03-18T08:57:55.569026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    11\n",
      "B     1\n",
      "Name: type, dtype: int64\n",
      "A    0.916667\n",
      "B    0.083333\n",
      "Name: type, dtype: float64\n",
      "1     12\n",
      "55    12\n",
      "72    12\n",
      "71    12\n",
      "67    12\n",
      "      ..\n",
      "37    10\n",
      "48     8\n",
      "50     6\n",
      "39     4\n",
      "43     2\n",
      "Name: department, Length: 80, dtype: int64\n",
      "1     0.012917\n",
      "55    0.012917\n",
      "72    0.012917\n",
      "71    0.012917\n",
      "67    0.012917\n",
      "        ...   \n",
      "37    0.010764\n",
      "48    0.008611\n",
      "50    0.006459\n",
      "39    0.004306\n",
      "43    0.002153\n",
      "Name: department, Length: 80, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Подсчитать количество магазинов каждого типа\n",
    "store_counts = store_types['type'].value_counts()\n",
    "print(store_counts)\n",
    "\n",
    "# Получить долю магазинов каждого типа\n",
    "store_props = store_types['type'].value_counts(normalize=True)\n",
    "print(store_props)\n",
    "\n",
    "# Подсчитать количество каждого номера отдела и отсортировать\n",
    "dept_counts_sorted = store_depts['department'].value_counts(sort=True)\n",
    "print(dept_counts_sorted)\n",
    "\n",
    "# Получить долю отделов каждого номера и отсортировать\n",
    "dept_props_sorted = store_depts['department'].value_counts(sort=True, normalize=True)\n",
    "print(dept_props_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264fffd5",
   "metadata": {},
   "source": [
    "### Какой процент продаж произошел в каждом типе магазина?\n",
    "\n",
    "Хотя `.groupby()` полезен, вы можете вычислить группированные сводные статистики и без его использования.\n",
    "\n",
    "Walmart различает три типа магазинов: \"суперцентры\", \"скидочные магазины\" и \"рынки в районе\", закодированные в этом наборе данных как тип \"A\", \"B\" и \"C\". В этом упражнении вы будете вычислять общие продажи в каждом типе магазина, не используя `.groupby()`. Затем вы сможете использовать эти числа, чтобы увидеть, какая часть общих продаж Walmart пришлась на каждый тип.\n",
    "\n",
    "Доступен DataFrame `sales`, и pandas импортирован как pd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e59381",
   "metadata": {},
   "source": [
    "####  Инструкции\n",
    "\n",
    "- Посчитайте общие еженедельные продажи по всему набору данных.\n",
    "- Выберите магазины типа \"A\" и посчитайте их общие еженедельные продажи.\n",
    "- Сделайте то же самое для магазинов типа \"B\" и \"C\".\n",
    "- Объедините результаты типов A/B/C в список и разделите на `sales_all`, чтобы получить долю продаж по типу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cafb7875",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T09:18:09.578935Z",
     "start_time": "2024-03-18T09:18:09.567595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9097747 0.0902253 0.       ]\n"
     ]
    }
   ],
   "source": [
    "# Вычисление общих еженедельных продаж\n",
    "sales_all = sales[\"weekly_sales\"].sum()\n",
    "\n",
    "# Выбор магазинов типа A и вычисление общих еженедельных продаж\n",
    "sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Выбор магазинов типа B и вычисление общих еженедельных продаж\n",
    "sales_B = sales[sales[\"type\"] == \"B\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Выбор магазинов типа C и вычисление общих еженедельных продаж\n",
    "sales_C = sales[sales[\"type\"] == \"C\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Получение доли для каждого типа\n",
    "sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb093288",
   "metadata": {},
   "source": [
    "### Вычисления с помощью .groupby()\n",
    "\n",
    "Метод `.groupby()` значительно упрощает жизнь. В этом упражнении вы выполните те же вычисления, что и в прошлый раз, за исключением того, что будете использовать метод .`groupby()`. Вы также выполните вычисления на данных, сгруппированных по двум переменным, чтобы увидеть, отличаются ли продажи в зависимости от типа магазина и является ли неделя праздничной или нет.\n",
    "\n",
    "Доступен DataFrame `sales`, и `pandas` загружен как pd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3061e3e9",
   "metadata": {},
   "source": [
    "#### Инструкции 1/2\n",
    "\n",
    "- Сгруппируйте данные `sales` по `\"type\"`, возьмите сумму `\"weekly_sales\"` и сохраните как `sales_by_type`.\n",
    "- Рассчитайте долю продаж для каждого типа магазина, разделив на сумму `sales_by_type`. Присвойте переменной `sales_propn_by_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "585f69ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:18:58.648351Z",
     "start_time": "2024-03-18T12:18:58.641337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "A    0.909775\n",
      "B    0.090225\n",
      "Name: weekly_sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Группировка по типу; вычисление общих еженедельных продаж\n",
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "# Получение доли для каждого типа\n",
    "sales_propn_by_type =  sales_by_type / sales_all\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333853e9",
   "metadata": {},
   "source": [
    "#### Инструкции 2/2\n",
    "\n",
    "Сгруппируйте данные `sales` по `\"type\"` и `\"is_holiday\"`, возьмите сумму `weekly_sales` и сохраните как `sales_by_type_is_holiday`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa51904b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:20:50.061181Z",
     "start_time": "2024-03-18T12:20:50.052850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type  is_holiday\n",
      "A     False         2.336927e+08\n",
      "      True          2.360181e+04\n",
      "B     False         2.317678e+07\n",
      "      True          1.621410e+03\n",
      "Name: weekly_sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Группировка по типу и is_holiday; вычисление общих еженедельных продаж\n",
    "sales_by_type_is_holiday = sales.groupby(['type','is_holiday'])['weekly_sales'].sum()\n",
    "print(sales_by_type_is_holiday)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6bf64c",
   "metadata": {},
   "source": [
    "### Несколько сгруппированных сводных статистик\n",
    "\n",
    "Ранее в этой главе вы видели, что метод `.agg()` полезен для вычисления нескольких статистик по нескольким переменным. Он также работает с сгруппированными данными. NumPy, который импортирован как np, имеет множество различных функций сводных статистик, включая: `np.min, np.max, np.mean и np.median.`\n",
    "\n",
    "Доступен DataFrame `sales`, и pandas импортирован как pd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c631677",
   "metadata": {},
   "source": [
    "#### Инструкции\n",
    "\n",
    "- Получите `min, max, mean` и `median для weekly_sales` для каждого типа магазина, используя `.groupby()` и `.agg().` Сохраните это как `sales_stats`. Обязательно используйте функции numpy!\n",
    "- Получите `min, max, mean` и `median` для `unemployment` и `fuel_price_usd_per_l` для каждого типа магазина. Сохраните это как `unemp_fuel_stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f34a8162",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:52:18.841868Z",
     "start_time": "2024-03-18T12:52:18.804130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         min        max          mean    median\n",
      "type                                           \n",
      "A    -1098.0  293966.05  23674.667242  11943.92\n",
      "B     -798.0  232558.51  25696.678370  13336.08\n"
     ]
    },
    {
     "data": {
      "text/plain": "     unemployment                         fuel_price_usd_per_l            \\\n              min    max      mean median                  min       max   \ntype                                                                       \nA           3.879  8.992  7.972611  8.067             0.664129  1.107410   \nB           7.170  9.765  9.279323  9.199             0.760023  1.107674   \n\n                          \n          mean    median  \ntype                      \nA     0.744619  0.735455  \nB     0.805858  0.803348  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">unemployment</th>\n      <th colspan=\"4\" halign=\"left\">fuel_price_usd_per_l</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>min</th>\n      <th>max</th>\n      <th>mean</th>\n      <th>median</th>\n      <th>min</th>\n      <th>max</th>\n      <th>mean</th>\n      <th>median</th>\n    </tr>\n    <tr>\n      <th>type</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A</th>\n      <td>3.879</td>\n      <td>8.992</td>\n      <td>7.972611</td>\n      <td>8.067</td>\n      <td>0.664129</td>\n      <td>1.107410</td>\n      <td>0.744619</td>\n      <td>0.735455</td>\n    </tr>\n    <tr>\n      <th>B</th>\n      <td>7.170</td>\n      <td>9.765</td>\n      <td>9.279323</td>\n      <td>9.199</td>\n      <td>0.760023</td>\n      <td>1.107674</td>\n      <td>0.805858</td>\n      <td>0.803348</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Для каждого типа магазина агрегируйте weekly_sales: получите минимум, максимум, среднее и медиану\n",
    "sales_stats = sales.groupby('type')['weekly_sales'].agg([min, max, np.mean, np.median])\n",
    "\n",
    "# Выведите на экран sales_stats\n",
    "print(sales_stats)\n",
    "\n",
    "# Для каждого типа магазина агрегируйте unemployment и fuel_price_usd_per_l: получите минимум, максимум, среднее и медиану\n",
    "unemp_fuel_stats = sales.groupby('type')[['unemployment','fuel_price_usd_per_l']].agg([min, max, np.mean, np.median])\n",
    "\n",
    "# Выведите на экран unemp_fuel_stats\n",
    "display(unemp_fuel_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f37e01",
   "metadata": {},
   "source": [
    "### Сводная таблица по одной переменной\n",
    "\n",
    "Таблицы сводных данных - стандартный способ агрегирования информации в электронных таблицах.\n",
    "\n",
    "В библиотеке pandas сводные таблицы по сути являются еще одним способом выполнения групповых вычислений. То есть метод .`pivot_table()` представляет собой альтернативу .`groupby()`.\n",
    "\n",
    "В этом упражнении вы будете использовать `.pivot_table()` для выполнения расчетов и воспроизведения вычислений, проведенных в предыдущем уроке с использованием `.groupby()`.\n",
    "\n",
    "Доступен DataFrame `sales`, и pandas импортирован как pd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f157a84",
   "metadata": {},
   "source": [
    "#### 1/3\n",
    "\n",
    "Получите среднее значение `weekly_sales` по типу с помощью .`pivot_table()` и сохраните как `mean_sales_by_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dd8e9e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T10:39:50.118858Z",
     "start_time": "2024-03-23T10:39:50.100885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      weekly_sales\n",
      "type              \n",
      "A     23674.667242\n",
      "B     25696.678370\n"
     ]
    }
   ],
   "source": [
    "# Сводная таблица для средних еженедельных продаж для каждого типа магазина\n",
    "mean_sales_by_type = sales.pivot_table(values='weekly_sales', index='type')\n",
    "\n",
    "# Вывод mean_sales_by_type на экран\n",
    "print(mean_sales_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a95ae1",
   "metadata": {},
   "source": [
    "####  2/3\n",
    "\n",
    "Получите среднее и медиану (используя функции NumPy) для `weekly_sales` по типу с помощью .`pivot_table()` и сохраните как `mean_med_sales_by_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f0c64bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T10:42:40.399738Z",
     "start_time": "2024-03-23T10:42:40.365829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_holiday         False      True \n",
      "type                               \n",
      "A           23768.583523  590.04525\n",
      "B           25751.980533  810.70500\n"
     ]
    }
   ],
   "source": [
    "# Сводная таблица для средних еженедельных продаж по типу магазина и празднику\n",
    "mean_sales_by_type_holiday = sales.pivot_table(values='weekly_sales', index='type', aggfunc=np.mean, columns='is_holiday')\n",
    "\n",
    "# Вывод mean_sales_by_type_holiday на экран\n",
    "print(mean_sales_by_type_holiday)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62870466",
   "metadata": {},
   "source": [
    "### Заполнение отсутствующих значений и подсчет суммы значений с помощью сводных таблиц\n",
    "\n",
    "Метод `.pivot_table()` имеет несколько полезных аргументов, включая `fill_value` и `margins`.\n",
    "\n",
    "- `fill_value` заменяет отсутствующие значения на реальное значение (известное как импутация). Чем заменять отсутствующие значения - это достаточно большая тема, чтобы иметь свой собственный курс (работа с отсутствующими данными в Python), но самый простой способ - заменить их фиктивным значением.\n",
    "- `margins` - это сокращение для случая, когда вы создали сводную таблицу по двум переменным, но также хотели бы создать сводные таблицы для каждой из этих переменных по отдельности: он дает итоги строк и столбцов содержимого сводной таблицы.\n",
    "В этом упражнении вы попрактикуетесь в использовании этих аргументов, чтобы улучшить свои навыки работы со сводными таблицами, что поможет вам более эффективно обрабатывать числовые данные!\n",
    "\n",
    "Доступен DataFrame `sales`, и `pandas` импортирован как pd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4199fbe",
   "metadata": {},
   "source": [
    "#### Инструкции 1/2\n",
    "\n",
    "- Выведите средние еженедельные продажи по отделу и типу, заполнив все отсутствующие значения нулями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd0f6add",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T10:56:07.184593Z",
     "start_time": "2024-03-23T10:56:07.168195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type                    A              B\n",
      "department                              \n",
      "1            30961.725379   44050.626667\n",
      "2            67600.158788  112958.526667\n",
      "3            17160.002955   30580.655000\n",
      "4            44285.399091   51219.654167\n",
      "5            34821.011364   63236.875000\n",
      "...                   ...            ...\n",
      "95          123933.787121   77082.102500\n",
      "96           21367.042857    9528.538333\n",
      "97           28471.266970    5828.873333\n",
      "98           12875.423182     217.428333\n",
      "99             379.123659       0.000000\n",
      "\n",
      "[80 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Вывести средние еженедельные продажи по отделу и типу; заполнить отсутствующие значения нулями\n",
    "\n",
    "print(sales.pivot_table(values='weekly_sales', index='department', columns='type', aggfunc=np.mean, fill_value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8157c713",
   "metadata": {},
   "source": [
    "#### Инструкции 2/2\n",
    "\n",
    "Выведите средние еженедельные продажи по отделу и типу, заполнив все отсутствующие значения нулями и суммируйте все строки и столбцы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8fb6ec9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T10:58:47.377509Z",
     "start_time": "2024-03-23T10:58:47.329938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type                   A              B           All\n",
      "department                                           \n",
      "1           30961.725379   44050.626667  32052.467153\n",
      "2           67600.158788  112958.526667  71380.022778\n",
      "3           17160.002955   30580.655000  18278.390625\n",
      "4           44285.399091   51219.654167  44863.253681\n",
      "5           34821.011364   63236.875000  37189.000000\n",
      "...                  ...            ...           ...\n",
      "96          21367.042857    9528.538333  20337.607681\n",
      "97          28471.266970    5828.873333  26584.400833\n",
      "98          12875.423182     217.428333  11820.590278\n",
      "99            379.123659       0.000000    379.123659\n",
      "All         23674.667242   25696.678370  23843.950149\n",
      "\n",
      "[81 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Вывести средние еженедельные продажи по отделу и типу; заполнить отсутствующие значения нулями; подсчитать сумму всех строк и столбцов\n",
    "print(sales.pivot_table(values='weekly_sales', index='department', columns='type', aggfunc=np.mean, fill_value=0, margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d7851de28b313dbf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
